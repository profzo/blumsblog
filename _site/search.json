[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog Ich lade hier meine Projekte aus meiner Data-Science-Vorlesung hoch. Und vielleicht mal mehr."
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_summary | default(““, true) }}\n\n\n\n\n\n{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ dataset_structure | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_structure | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_summary | default(““, true) }}\n\n\n\n\n\n{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}\n\n\n\n\nUse the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n\n{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}\n\n\n\n\n\n\n{{ model_examination | default(“[More Information Needed]”, true)}}\n\n\n\n\nCarbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Use the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_examination | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Carbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "href": "dsiivirtualenv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "dsiivirtualenv/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "blumsblog",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "href": "dsiivirtualenv/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "title": "blumsblog",
    "section": "",
    "text": "Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Python Markdown Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE PYTHON MARKDOWN PROJECT ‘’AS IS’’ AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANY CONTRIBUTORS TO THE PYTHON MARKDOWN PROJECT BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/numpy/random/LICENSE.html",
    "href": "dsiivirtualenv/Lib/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "href": "dsiivirtualenv/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "title": "libjpeg-turbo Licenses",
    "section": "",
    "text": "libjpeg-turbo Licenses\nlibjpeg-turbo is covered by three compatible BSD-style open source licenses:\n\nThe IJG (Independent JPEG Group) License, which is listed in README.ijg\nThis license applies to the libjpeg API library and associated programs (any code inherited from libjpeg, and any modifications to that code.)\nThe Modified (3-clause) BSD License, which is listed below\nThis license covers the TurboJPEG API library and associated programs, as well as the build system.\nThe zlib License\nThis license is a subset of the other two, and it covers the libjpeg-turbo SIMD extensions.\n\n\n\nComplying with the libjpeg-turbo Licenses\nThis section provides a roll-up of the libjpeg-turbo licensing terms, to the best of our understanding.\n\nIf you are distributing a modified version of the libjpeg-turbo source, then:\n\nYou cannot alter or remove any existing copyright or license notices from the source.\nOrigin\n\nClause 1 of the IJG License\nClause 1 of the Modified BSD License\nClauses 1 and 3 of the zlib License\n\nYou must add your own copyright notice to the header of each source file you modified, so others can tell that you modified that file (if there is not an existing copyright header in that file, then you can simply add a notice stating that you modified the file.)\nOrigin\n\nClause 1 of the IJG License\nClause 2 of the zlib License\n\nYou must include the IJG README file, and you must not alter any of the copyright or license text in that file.\nOrigin\n\nClause 1 of the IJG License\n\n\nIf you are distributing only libjpeg-turbo binaries without the source, or if you are distributing an application that statically links with libjpeg-turbo, then:\n\nYour product documentation must include a message stating:\nThis software is based in part on the work of the Independent JPEG Group.\nOrigin\n\nClause 2 of the IJG license\n\nIf your binary distribution includes or uses the TurboJPEG API, then your product documentation must include the text of the Modified BSD License (see below.)\nOrigin\n\nClause 2 of the Modified BSD License\n\n\nYou cannot use the name of the IJG or The libjpeg-turbo Project or the contributors thereof in advertising, publicity, etc.\nOrigin\n\nIJG License\nClause 3 of the Modified BSD License\n\nThe IJG and The libjpeg-turbo Project do not warrant libjpeg-turbo to be free of defects, nor do we accept any liability for undesirable consequences resulting from your use of the software.\nOrigin\n\nIJG License\nModified BSD License\nzlib License\n\n\n\n\nThe Modified (3-clause) BSD License\nCopyright (C)2009-2022 D. R. Commander. All Rights Reserved. Copyright (C)2015 Viktor Szathmáry. All Rights Reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the libjpeg-turbo Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS”, AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nWhy Three Licenses?\nThe zlib License could have been used instead of the Modified (3-clause) BSD License, and since the IJG License effectively subsumes the distribution conditions of the zlib License, this would have effectively placed libjpeg-turbo binary distributions under the IJG License. However, the IJG License specifically refers to the Independent JPEG Group and does not extend attribution and endorsement protections to other entities. Thus, it was desirable to choose a license that granted us the same protections for new code that were granted to the IJG for code derived from their software."
  },
  {
    "objectID": "dsiivirtualenv/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "href": "dsiivirtualenv/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "title": "blumsblog",
    "section": "",
    "text": "Silk icon set 1.3 by Mark James mjames@gmail.com\nhttp://www.famfamfam.com/lab/icons/silk/\nLicense: CC-BY-2.5 or CC-BY-3.0"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "X, vormals Twitter, ist schon lange als Hexenkessel bzw. Sammelbecken für Internet-Trolle bekannt. Nirgendwo sonst im Internet wird so prominent polarisiert, getrollt oder beleidigt. Unter anderem deshalb bietet sich die Plattform an, um die Beiträge dr Mitglieder zu analysieren und Hassrede zu identifizieren. In diesem Beitrag soll eine Auswahl solcher Tweets genauer untersucht werden. Zuerst wird der Datensatz pr Explorative Datenanalyse dargestellt. Danach werden mehrere Klassifikationen nach Hate Speech vorgenommen mittels verschiedener Methoden des Text-Minings. Viel Vergnügen!\n\n\n\nlibrary(tidyverse)  # data manipulation & plotting\nlibrary(tidytext)   # provides additional text mining functions, sentiments\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`\nlibrary(tidymodels) \nlibrary(stopwords)  # Stopwörter entfernen\nlibrary(wordcloud)  # Wordclouds erstellen\nlibrary(RColorBrewer)# für wordcloud\nlibrary(sentimentr)\nlibrary(widyr)      # Ähnlichkeit/ pmi berechnen mit widyr_svd\nlibrary(irlba)      # widely_svd()\nlibrary(furrr)      # für future_map bei pmi berechnen\nlibrary(textrecipes)\nlibrary(tokenizers)\nlibrary(syuzhet) \nlibrary(lexicon)\nlibrary(xgboost)\nlibrary(tictoc)\nlibrary(vip)\nlibrary(caret)\nlibrary(pROC)\n\n\n\nColor Palettes for Color Blindness: Okabe-Ito palette as suggested by Okabe & Ito (2008) (https://jfly.uni-koeln.de/color/) palette.colors(palette = “Okabe-Ito”) black orange skyblue bluishgreen yellow “#000000” “#E69F00” “#56B4E9” “#009E73” “#F0E442” blue vermillion reddishpurple gray “#0072B2” “#D55E00” “#CC79A7” “#999999”\n\n\n\n\n\nd_hate &lt;- read_csv(datenpfad)\n\nRows: 5593 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (2): tweet, class\ndbl (1): id\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(d_hate)\n\nRows: 5,593\nColumns: 3\n$ id    &lt;dbl&gt; 0, 40, 63, 66, 67, 70, 75, 85, 90, 111, 116, 119, 120, 121, 123,~\n$ tweet &lt;chr&gt; \"!!! RT @mayasolovely: As a woman you shouldn't complain about c~\n$ class &lt;chr&gt; \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"~\n\n\n\n\n\nDer Datensatz besteht aus 5593 Tweets, wovon kanpp 26% als Hate Speech klassifiziert wurden.\n\nggplot(d_hate, aes(x = \"\", y = \"\", fill = class)) +\n  geom_col() +\n  coord_polar(theta = \"y\") +\n   scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_void()\n\n\n\n\nWir können schon beim ersten Überfliegen des Datensatzes sehen, dass uns harter Tobak erwartet: Trans- & Homofeindlichkeit, Rassismus, Misogynie…\n“Why people think gay marriage is okay is beyond me.[…]” id 598 “Those n*****s disgust me. They should have dealt with 100 years ago, we wouldn’t be having these problems now.” id 2483\nAber dazu später mehr. Zuerst ein paar Grundlagen: Auch fällt auf, dass viele Usernames und URL’s inbegriffen sind. Diese sind vielleicht nicht relevant für unsere Analyse und sollten später evtl. aussortiert werden (starts_with(“http”, “@”))\n\n\nUm einzelne Wörter graphisch darstellbar zu machen, zerlegen wir die Tweets in ihre einzelnen Strings, also Wörter. Da sich die Funktion unnest_tokens() hier allerdings nicht so gut anstellt, benötigen wir einen eigenen Tokenizer. Dieser ist so angepasst, dass Usernamen und Links in den Tweets nicht aufgenommen werden.\n\ntxt &lt;- \"@BabyAnimalPics: baby monkey bathtime http://t.co/7KPWAdLF0R Awwwwe! This is soooo ADORABLE!\"\n\nstr_split(txt, \"[:space:]+\") %&gt;%\n    map(~ str_remove_all(.x, \"@[^ ]+|https?[:graph:]+|^[:punct:]+|[:punct:]+\"))\n\n[[1]]\n [1] \"\"         \"baby\"     \"monkey\"   \"bathtime\" \"\"         \"Awwwwe\"  \n [7] \"This\"     \"is\"       \"soooo\"    \"ADORABLE\"\n\n\nDazu müssen noch alle möglichen Zahlen entfernt werden wie z.B. Unicodes von auf Twitter genutzten Emojis oder Geldbeträge. Alles zu einer Funktion kombiniert, könnte wie folgt aussehen:\n\ntokenize_words &lt;- function(x, lowercase = TRUE) {\n  if (lowercase)\n    x &lt;- str_to_lower(x)\n  \n  str_split(x, \"[:space:]\") %&gt;%\n    map(~ str_remove_all(.x, \n          \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|^[:punct:]+|[:punct:]+|\\\\d+\")) %&gt;% \n    unlist()\n}\n\nMal probieren ob es klappt:\n\nd_hate_regtok &lt;-\n  d_hate %&gt;%\n    mutate(word = map(tweet, tokenize_words)) %&gt;% \n  unnest(cols = word)%&gt;% \n  select(-tweet) %&gt;% \n  filter(!word == \"\")\nhead(d_hate_regtok)\n\n\n\n  \n\n\n\nSchon besser!\n\n\n\nEs befinden sich noch einige Strings in der Liste, die keine (analysierbaren) Wörter darstellen. Da hilft nur eines: Stopwörter entfernen! Hierzu kombiniere ich einige gängige Listen und ergänze sie mit einer eigenen, auf den Datensatz zugeschnittene Liste (z.B. “rt” ist die Abkürzung von “retweet”, “yall” als umgangssprachliche Form von “you all”).\n\nsw_snowball &lt;- get_stopwords(source = \"snowball\")\nsw_iso &lt;- get_stopwords(source = \"stopwords-iso\")\nsw_smart &lt;- get_stopwords(source = \"smart\")\nsw_tweet &lt;- tibble(word = c(\"rt\", \"da\", \"yall\", \"ur\", \"yo\", \"dat\", \"smh\", \"tho\", \"ya\", \"bout\", \"em\", \"dis\", \"bc\", \"dem\", \"ima\", \"|\", \"dc\", \"$\", \"+\"))\nsw_combi &lt;- \n  bind_rows(sw_snowball, sw_iso, sw_smart, sw_tweet) %&gt;% \n  select(-lexicon)\n\nd_hate_tok_wstop &lt;- \n  d_hate_regtok %&gt;% \n  anti_join(sw_combi)\n\nJoining with `by = join_by(word)`\n\nhead(d_hate_tok_wstop)\n\n\n\n  \n\n\n\n\n\n\nNun, da die Tweets in ihre einzelnen Wörter aufgeteilt und bereinigt sind, können wir wunderbar visualisieren was der Datensatz bereithält.\nWelche Wörter kommen am häufigsten vor?\n\nd_hate_tok_wstop %&gt;%\n  count(word, sort = TRUE) %&gt;% \n  slice_max(order_by = n, n = 20) %&gt;% \n  mutate(word = factor(word)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, n), x = n) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nDas ganze nochmal, aber jetzt nach Klassifikation sortiert:\n\nlibrary(reshape2)\n\n\nAttache Paket: 'reshape2'\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    smiths\n\nd_hate_tok_wstop %&gt;% \n  count(word, class, sort = TRUE) %&gt;%\n  acast(word ~ class, value.var = \"n\", fill = 0) %&gt;%\n  comparison.cloud(colors = c(\"#D55E00\", \"#56B4E9\",\n                              title.bg.colors=\"white\"),\n                   max.words = 100)\n\n\n\n\n“Man sieht: Es sind Schimpfwörter im Haus!” Das könnte für die weitere Analyse/ Klassifikation interessantwerden, ebenso wie mögliche Codewörter wie “brownie” (Personen mit dunkler Hautfarbe) oder “birds” (Frauen).\n\n\n\nDie Sentimentanalyse erkennt und bewertet den überwiegende “Ton” oder die “Stimmung” eines Textes. Dieser Prozess kann auf einzelne Sätze, Absätze oder sogar auf gesamte Dokumente angewendet werden. Wir konzentrieren uns hier einmal auf einzelne Wörter mithilfe des Lexikons afinn und einmal auf die Bewertung im Kontext eines ganzen Satzes mit dem Paket sentimentr.\nMit afinn:\n\nAFINN &lt;- get_sentiments(lexicon = \"afinn\")\n\n\nd_hate_senti &lt;-\nd_hate_tok_wstop %&gt;% \n  inner_join(AFINN, by = \"word\")\n\n\nd_hate_senti %&gt;% \n  group_by(class) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% round(2))\n\n\n\n  \n\n\n\nEs gibt ungefähr gleich viele polarisierende Wörter auf Seiten der Hate Speech und der Übrigen. Jedoch sind die Wörter unter Hate Speech deutlich stärker emotional negativ aufgeladen.\n\nd_hate_senti %&gt;% \n  ggplot() +\n  geom_density(aes(value, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nMit sentimentr:\n\nhate_sentir &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  sentiment() %&gt;% \n  filter(!word_count == 0)\n\n\nhate_sentir %&gt;% \n  ggplot() +\n  geom_density(aes(sentiment, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nIm Vergleich zur Sentimenteinteilung von afinn sieht man hier eine ganz klare Spitze beim Wert der neutralen Bestandteile. Das liegt vor allem an der ungenauen Eintilung vom Befehl get_sentences(), der etliche Nicht-Sätze erstellt, die als neutral gewertet werden. Das könnte aber auch an der unterschiedlichen Herangehensweise, das Sentiment über die einzelnen Wörter bzw. im Kontext des gesamten Satzes zu ermitteln. Einzelne Wörter sind einfacher zu erkennen und eindeutiger zu bewerten.\nMit sentimentr kann man zusätzlich noch die Emotionen und Schimpfwörter analysieren.\n\nhate_emos &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion() %&gt;% \n  filter(!word_count == 0,\n         !emotion_count == 0)\n\n\nhate_emos %&gt;% \n  ggplot(aes(emotion_type, fill = class, colour = class)) +\n  geom_bar() +\n  scale_x_discrete(guide = guide_axis(angle = 60)) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDas ist ein sehr großer Datensatz, deshalb will ich für jede id/ jeden Tweet die dominante Emotion herausfinden und darauf basierend den Datensatz verschlanken.\n\nhate_emos2 &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion()\n\ndominant_emotion_df &lt;- \n  hate_emos2 %&gt;%\n  group_by(id, emotion_type) %&gt;%\n  summarize(weighted_score = sum(emotion_count * emotion)) %&gt;%\n  dplyr::slice(which.max(weighted_score)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\ndominant_emo_hate &lt;-\n  merge(d_hate, dominant_emotion_df, by = \"id\")\n\ndominant_emo_hate %&gt;% \n  ggplot(aes(class, emotion_type)) +\n  geom_bin2d() + \n  theme_minimal()\n\n\n\n\nKlappt!\nZwar muss bei dieser Grafik beachtet werden, dass der Anteil von other generell sehr viel größer ist, als der von hate speech und dementsprechend heller ist. Trotzdem kann man hier gut erkennen, welche Emotionen in den Tweets mit Hate Speech wohl vorherrscht: Wut, Ekel, Niedergeschlagenheit\nNun zu den Schimpfwörtern:\n\nhate_prof &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  profanity() %&gt;% \n  filter(!word_count == 0)\n\nKritik: Das Schimpfwortlexikon von sentimentr listet das N-Wort in manchen Schreibweisen nicht als Schimpfwort!\n\nhate_prof %&gt;% \n  ggplot(aes(element_id, profanity_count, fill = class)) +\n  geom_bin_2d() +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDie Tweets, die einen hohen Anteil an Schimpfwörtern haben, sind eher unter hate speech gefallen, als andere.\n\n\n\nWord Embeddings sind eine Methode, um Textdaten als Vektoren von Zahlen darzustellen, basierend auf einem großen Textkorpus. Anders als bei tf_idf wird dabei die semantische Bedeutung aus dem Kontext der Wörter erfasst und die Textinformationen auf einen sehr dichte Raum reduziert. Aus diesem Grund tachen sie auch hier auf. Außerdem können wir dadurch erkennen, in welchem Kontext unsere angeblichen Codewörter stehen, und beurteilen, ob sie hier in erster Linie als solche verwendet werden.\n\ntidy_hate &lt;-\n  d_hate_tok_wstop %&gt;% \n  add_count(word) %&gt;% \n  filter(n &gt;= 15) %&gt;% \n  select(-n)\n\n\nnested_hate &lt;-\n  tidy_hate %&gt;% \n  nest(words = c(word))\n\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x,  # Syntax ähnlich zu purrr::map()\n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n    safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\n\nhate_pmi &lt;- nested_hate %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;% \n  unnest(words) %&gt;% \n  unite(window_id, id, window_id) %&gt;% \n  pairwise_pmi(word, window_id)\n\nhate_pmi\n\n\n\n  \n\n\n\n\nhate_word_vectors &lt;- hate_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\n-&gt; Um zu entdecken, welche Wörter sich am nächsten stehen. Hier kommen die erwähnten Codewörter ins Spiel.\n\nnearest_neighbors &lt;- function(df, token) {\n  df %&gt;%\n    widely(\n      ~ {\n        y &lt;- .[rep(token, nrow(.)), ]\n        res &lt;- rowSums(. * y) / \n          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))\n        \n        matrix(res, ncol = 1, dimnames = list(x = names(res)))\n      },\n      sort = TRUE\n    )(item1, dimension, value) %&gt;%\n    select(-item2)\n}\n\nFür Bird:\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"bird\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#CC79A7\") +\n  theme_minimal()\n\n\n\n\nDie Worte mit dem höchsten Wert lassen sich plausibel erklären und scheinen nicht sehr viel mit einem möglichen frauenverachtenden Codewort zu tun zu haben.(play, Flappy Birds, Angry Birds, games)\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"brownie\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nHier beziehen sich die meisten Wörter auch auf das Gebäck, statt auf Menschen Bezug zu nehmen.\nUm nochmal sicher zu gehen, ob dieses Vorgehen auch verlässlich ist, probieren wir es mit einem offensichtlichen Begriff\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"nigga\")\n\n\n\n  \n\n\n\nDefinitiv im Kontext negativerer Wörter!\nUm diese Embeddings für das spätere Modell zugänglich zu machen folgen noch ein paar Schritte.\n\nword_matrix &lt;- tidy_hate %&gt;%\n  count(id, word) %&gt;%\n  cast_sparse(id, word, n) \n\nembedding_matrix &lt;- hate_word_vectors %&gt;%\n  cast_sparse(item1, dimension, value)\n\n#doc_matrix &lt;- word_matrix %*% embedding_matrix\n#dim(doc_matrix)\n\n\nprint(dim(word_matrix))\n\n[1] 5235  309\n\nprint(dim(embedding_matrix))\n\n[1] 307 100\n\n\n\ndiff_matrix &lt;- dim(word_matrix) != dim(embedding_matrix)\ndiff_matrix\n\n[1] TRUE TRUE\n\n\nAus irgendeinem Grund gibt es einen Unterschied in den Matrizen, sodass ich sie nicht verbinden kann. Schade!\n\n\n\nn-grams stellen eine weitere Möglichkeit der Textanalyse dar, um Muster, Zusammenhänge und Beziehungen zwischen aufeinanderfolgenden Wörtern zu analysieren. Bigramme sind eine Sequenz von zwei aufeinanderfolgenden Elementen oder - in unserem Fall - Wörtern in einem Text. Als kleine Ergänzung zu den mögliche Codewörtern unter Word-Embeddings möchte ich hier noch einmal herausfinden welche Wörter denn wirklich häufig zusammen verwendet werden.\n\nbigrams_hate &lt;-\n  d_hate %&gt;% \n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2)\n\n\nsw_erg &lt;- tibble(word = c(\"t.co\", \"128557\", \"128514\", \"ho\", \"8230\", \"9733\", \"https\", \"http\"))\nadded_sw &lt;- bind_rows(sw_combi, sw_erg)\n\n\nlibrary(igraph)\n\n(bigram_graph &lt;- bigrams_hate %&gt;% \n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %&gt;%\n        filter(!word1 %in% added_sw$word,\n               !word2 %in% added_sw$word) %&gt;%\n        count(word1, word2, sort = TRUE) %&gt;%\n        unite(\"bigram\", c(word1, word2), sep = \" \") %&gt;%\n        filter(n &gt; 10) %&gt;%\n        graph_from_data_frame()\n)\n\nIGRAPH ce4131e DN-- 44 28 -- \n+ attr: name (v/c)\n+ edges from ce4131e (vertex names):\n [1] white trash   -&gt;66 flappy bird   -&gt;40 charlie crist -&gt;34 charlie sheen -&gt;26\n [5] charlie brown -&gt;25 derek jeter   -&gt;24 ass nigga     -&gt;22 charlie baker -&gt;21\n [9] trash talk    -&gt;21 0221 24       -&gt;19 622 0221      -&gt;19 asian massage -&gt;19\n[13] park slope    -&gt;19 rated spa     -&gt;19 uncle tom     -&gt;19 128525 128525 -&gt;17\n[17] yankee stadium-&gt;17 happy birthday-&gt;16 bitch ass     -&gt;15 rick scott    -&gt;15\n[21] 718 622       -&gt;14 ice cream     -&gt;14 red sox       -&gt;13 white people  -&gt;13\n[25] colored folk  -&gt;12 black people  -&gt;11 fucking faggot-&gt;11 trash 8221    -&gt;11\n\n\n\nlibrary(ggraph)\nset.seed(42)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n        geom_edge_link() +\n        geom_node_point(color = \"#CC79A7\", size = 5) +\n        geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n        theme_void()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDas mit Abstand am häufigsten vorkommende Bigramm ist “white trash”, dicht gefolgt von “flappy bird”. Anscheinend mussten viele ihren Frust an der digitalen Tastatur auslassen, nachdem sie das Spiel gespielt haben… Rassistsche und beleidigende Äußerungen wie “uncle tom” und “fucking faggot” sind ebenfalls vertreten, sowie das Stadion der New York Yankees und deren erfolgreicher Spieler Derek Jeter.\n\n\n\n\nJetzt soll es aber endlich um die Vorhersage von Hate Speech gehen. Zuerst bleiben wir noch in R und bauen ein Klassifizierungsmodell für Hate Speech in tidymodels.Danach geht es weiter in Python und wir nutzen ein Large Language Model (LLM) für eine Zero-Shot-Learning-Vorhersage, also ohne vorheriges Fine-Tuning des LLM.\n\n\n\nhate_for_rec &lt;-\n  d_hate %&gt;% \n  mutate(tweet = str_remove_all(tweet, \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|\\\\d+\"))\n\n\nset.seed(42)\nhate_split &lt;- initial_split(hate_for_rec, strata = class)\n\ntrain_hate &lt;- training(hate_split)\ntest_hate &lt;- testing(hate_split)\n\n\n\n\nWir brauchen noch folgende Listen vorab, da sich die Befehle von sentimentr schlecht in ein recipe einfügen lassen. Das im default verwendete Schimpfwort-Lexikon von sentimentr ergänze ich noch um ein anderes mit rassistischem Vokabular.\n\ndata(hash_sentiment_jockers_rinker)\nView(hash_sentiment_jockers_rinker)\nhash &lt;- hash_sentiment_jockers_rinker %&gt;% \n  rename(word = x,\n         value = y)\n\nprofal &lt;- unique(tolower(profanity_alvarez)) \ndata(\"profanity_racist\")\nprofanity &lt;- as_tibble(c(profal, profanity_racist))\nprofanity &lt;- profanity %&gt;% \n  rename(word = value) %&gt;% \n  mutate(value = 1)\n\n\nrec1 &lt;-\n  recipe(class ~ ., data = train_hate) %&gt;% \n  update_role(id, new_role = \"id\") %&gt;% \n  update_role(tweet, new_role = \"ignore\") %&gt;% \n  step_text_normalization(tweet) %&gt;% \n  step_mutate(senta = get_sentiment(tweet, method = \"afinn\"),\n              sentr = get_sentiment(tweet, method = \"custom\", lexicon = hash), \n              profan = get_sentiment(tweet, method = \"custom\", lexicon = profanity))%&gt;% \n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_stopwords(tweet, custom_stopword_source = \"sw_combi\") %&gt;% \n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;% \n  step_tfidf(tweet) %&gt;% \n  step_zv(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nbaked &lt;- bake(prep(rec1), new_data = NULL)\n\n\n\n\nmod1 &lt;-\n  boost_tree(mtry = tune(), \n            min_n = tune(), \n            trees = tune(),\n            tree_depth = tune(),\n            learn_rate = tune(),\n            loss_reduction = tune(),\n           mode = \"classification\") %&gt;% \n  set_engine(\"xgboost\", nthreads = 4)\n\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n\n\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(train_hate, v = 3, repeats = 2)\n\n\n\n\n\ntic()\nwf_tune &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl,\n    grid = 5, \n    seed = 42,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE, save_workflow = TRUE))\ntoc()\n\n723.02 sec elapsed\n\n\n\ntune::autoplot(wf_tune) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmetrics &lt;-\nwf_tune %&gt;% \n  collect_metrics() \nmetrics %&gt;% \n  arrange(-mean) %&gt;% \n  head()\n\n\n\n  \n\n\n\n-&gt; Preprocessor1_Model5 schneidet am besten ab.\n\n\n\n\nfinal_fit &lt;- \n  fit_best(wf_tune)\n\n[19:25:08] WARNING: amalgamation/../src/learner.cc:627: \nParameters: { \"nthreads\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nWelche Prädiktoren waren bei diesem Modell die wichtigsten?\n\nfinal_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 15, geom = \"point\") +\n  theme_minimal()\n\n\n\n\nWie schon in der EDA vermutet, nehmen Schimpfwörter einen sehr prominenten Wert in der Vorhersage ein. Zusammen mit den beiden Sentiment-Lexika und dem tf_idf-Wert für “white” führt es die Liste an.\n\n\n\n\npred_test &lt;- \n  final_fit %&gt;% \n  predict(new_data = test_hate) %&gt;% \n  bind_cols(test_hate)\n\n\npred_test1 &lt;-\n  pred_test %&gt;% \n  mutate(class = as_factor(class),\n         .pred_class = ifelse(.pred_class == \"hate speech\", 1, 0)) %&gt;% \n  mutate(class = ifelse(class == \"hate speech\", 1, 0))\n\nrocobj &lt;- \n  pred_test1 %&gt;% \n  roc(class, .pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#0072B2\", size = 1.5)\n\n\n\n\nObwohl unsere Vorhersage im Train-Sample eine accuracy von ca. 89% aufweist, liegt die ROC-Kurve für die Vorhersage auf das Test-Sample unter der Zufallslinie. Das bedeutet, dass unser Klassifikator schlechter ist, als zufällige Vorhersagen… Schade! Vielleicht ist es besser mit einem Transformer-Modell ;)\n\n\n\n\nWir nutzen Transformer-Modelle über die Huggingface-API für unser Zero-Shot-Learning. Ich habe mich hier für das Modell entschieden, das im Bezug auf Hate-Speech-Detection im Internet am häufigsten heruntergeladen wurde und sich in den Suchvorschlägen ganz oben befindet.\n\n\n\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\n\ntweet &lt;- test_hate$tweet\n\n\nhate_py = r.tweet\n\n\n\n\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\nresult = classifier(hate_py)\n\n\n\n\n…um die Ergebnisse der Vorhersage des Transformer-Modells vergleichen zu können.\n\nr_results &lt;- py$result\nhead(r_results)\n\n[[1]]\n[[1]]$label\n[1] \"nothate\"\n\n[[1]]$score\n[1] 0.9998609\n\n\n[[2]]\n[[2]]$label\n[1] \"nothate\"\n\n[[2]]$score\n[1] 0.8565221\n\n\n[[3]]\n[[3]]$label\n[1] \"nothate\"\n\n[[3]]$score\n[1] 0.6914555\n\n\n[[4]]\n[[4]]$label\n[1] \"hate\"\n\n[[4]]$score\n[1] 0.9997545\n\n\n[[5]]\n[[5]]$label\n[1] \"nothate\"\n\n[[5]]$score\n[1] 0.998069\n\n\n[[6]]\n[[6]]$label\n[1] \"nothate\"\n\n[[6]]$score\n[1] 0.9973779\n\n\n\nlabel &lt;- map(r_results, ~.$label)\n\npred_hate_py &lt;- \n  bind_cols(pred_test1, pred_py = unlist(label))\n\npred_hate_py &lt;- \n  pred_hate_py %&gt;%\n  mutate(pred_py = case_when(pred_py == \"hate\" ~ \"hate speech\",\n                             pred_py == \"nothate\" ~ \"other\"))  %&gt;%\n  mutate(pred_py = ifelse(pred_py == \"hate speech\", 1, 0))\n\n\nrocobj &lt;- \n  pred_hate_py %&gt;% \n  roc(class, pred_py)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#E69F00\", size = 1.5)\n\n\n\n\nOk, diese Form der “Kurve” weist Ähnlichkeiten zu der Kurve meines eigenen Modells auf… Allerdings hat dieses Modell einen steileren Anstieg, was beseutet, dass der Klassifikator mit höherer Genauigkeit positive Vorhersagen trifft, bevor viele falsch positive Vorhersagen gemacht werden.\n\ndiff_pred &lt;- \n  pred_hate_py %&gt;%\n  group_by(class) %&gt;%\n  count(pred_py != .pred_class)\ndiff_pred\n\n\n\n  \n\n\n\nIm direkten Vergleich haben das Transformer-Modell von Huggingface und mein tidymodels-Modell 269 Werte verschieden bewertet. Unter Nicht-Hate Speech gab es etwas mehr Unstimmigkeiten als bei Hate Speech selbst.\n\n\n\n\nDie Klassifikation von Hate Speech in sozialen Netzwerken bleibt ein Buch mit vielen Siegeln. Eine nahezu perfekte Vorhersage, wird es wahrscheinlich in naher Zukunft nicht geben. Dafür gibt es zu viele Limitationen des Algorithmus. Nicht ohne Grund beschweren sich v.a. viele Comedians/ Internet-Clowns, dass ihre Accounts aufgrund von angeblicher Hassrede/ Hetze gesperrt werden, obwohl sie sich satirisch/ ironisch äußern. Auch die in diesem Blog schon mehrfach erwähnten Codewörter für Beleidigungen/ rassistische Bezeichnugnen werden nicht weniger. Das kann man am Beispiel von Chinas Staatsoberhaupt Xi veranschaulichen.\n“According to the censorship log leaked by the social media app Xiaohongshu in 2020, 564 words were considered “sensitive” by the Chinese government when referring to Xi.” Xiao H., 2023 (https://wagingnonviolence.org/2023/04/how-subvversive-nicknames-for-china-present-xi-jinping-fuel-dissent/; abgerufen am 09.02.24)\n… und es werden nicht weniger! Dennoch stellt dieser Blog einige Ansatzpunkte und verschiedene Möglichkeiten dar, die zumindest ein paar der Siegel öffnen können. Alles darüber hinaus wird die Zukunft bringen!\n\n\n\nDieser Blogbeitrag orientiert sich an den Kursinhalten des Schwerpunktmoduls “Data Science 2” im Studiengang “Angewandte Wirtschafts- & Medienpsychologie”, betreut von Prof. Dr. habil. Sebastian Sauer.\nSebastian Sauer. (2023). sebastiansauer/datascience-text: v0.1.0 (Version draft1). Zenodo. https://doi.org/10.5281/zenodo.8279822.\n\n\n\nsessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28    stringi_1.7.6      ggraph_2.1.0       igraph_1.4.2      \n [5] reshape2_1.4.4     pROC_1.18.0        caret_6.0-94       lattice_0.20-45   \n [9] vip_0.4.1          tictoc_1.2         xgboost_1.6.0.1    lexicon_1.2.1     \n[13] syuzhet_1.0.7      tokenizers_0.3.0   textrecipes_1.0.3  furrr_0.3.1       \n[17] future_1.33.0      irlba_2.3.5.1      Matrix_1.5-4       widyr_0.1.5       \n[21] sentimentr_2.9.0   wordcloud_2.6      RColorBrewer_1.1-3 stopwords_2.3     \n[25] yardstick_1.1.0    workflowsets_1.0.1 workflows_1.1.3    tune_1.1.2        \n[29] rsample_1.2.0      recipes_1.0.9      parsnip_1.0.4      modeldata_1.2.0   \n[33] infer_1.0.5        dials_1.2.0        scales_1.2.1       broom_1.0.5       \n[37] tidymodels_1.0.0   see_0.8.1          report_0.5.7       parameters_0.21.0 \n[41] performance_0.10.3 modelbased_0.8.6   insight_0.19.2     effectsize_0.8.3  \n[45] datawizard_0.7.1   correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0   \n[49] tidytext_0.4.1     forcats_0.5.1      stringr_1.5.0      dplyr_1.1.2       \n[53] purrr_1.0.1        readr_2.1.2        tidyr_1.2.0        tibble_3.2.1      \n[57] ggplot2_3.4.4      tidyverse_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.3.1         backports_1.4.1      plyr_1.8.8          \n  [4] splines_4.1.3        listenv_0.9.0        SnowballC_0.7.0     \n  [7] digest_0.6.29        foreach_1.5.2        htmltools_0.5.5     \n [10] viridis_0.6.4        fansi_1.0.2          magrittr_2.0.2      \n [13] tzdb_0.3.0           graphlayouts_0.8.4   globals_0.16.2      \n [16] modelr_0.1.11        gower_1.0.1          vroom_1.6.1         \n [19] textshape_1.7.3      hardhat_1.3.0        colorspace_2.0-3    \n [22] ggrepel_0.9.3        rappdirs_0.3.3       rvest_1.0.3         \n [25] warp_0.2.0           haven_2.4.3          xfun_0.39           \n [28] crayon_1.5.2         jsonlite_1.8.4       survival_3.2-13     \n [31] iterators_1.0.14     glue_1.6.2           polyclip_1.10-4     \n [34] gtable_0.3.4         ipred_0.9-14         future.apply_1.11.0 \n [37] DBI_1.1.3            qdapRegex_0.7.8      Rcpp_1.0.8          \n [40] viridisLite_0.4.2    bit_4.0.5            GPfit_1.0-8         \n [43] textclean_0.9.3      stats4_4.1.3         lava_1.7.3          \n [46] prodlim_2023.03.31   htmlwidgets_1.6.2    httr_1.4.7          \n [49] ellipsis_0.3.2       farver_2.1.1         pkgconfig_2.0.3     \n [52] nnet_7.3-17          dbplyr_2.3.2         here_1.0.1          \n [55] utf8_1.2.2           labeling_0.4.3       tidyselect_1.2.0    \n [58] rlang_1.1.2          DiceDesign_1.9       munsell_0.5.0       \n [61] cellranger_1.1.0     tools_4.1.3          cli_3.6.0           \n [64] generics_0.1.3       evaluate_0.23        fastmap_1.1.0       \n [67] yaml_2.3.5           textdata_0.4.4       bit64_4.0.5         \n [70] ModelMetrics_1.2.2.2 knitr_1.37           fs_1.5.2            \n [73] tidygraph_1.2.3      nlme_3.1-155         xml2_1.3.3          \n [76] compiler_4.1.3       rstudioapi_0.15.0    png_0.1-8           \n [79] slider_0.3.0         reprex_2.0.2         tweenr_2.0.2        \n [82] lhs_1.1.6            vctrs_0.6.1          pillar_1.9.0        \n [85] lifecycle_1.0.4      data.table_1.14.8    R6_2.5.1            \n [88] gridExtra_2.3        janeaustenr_1.0.0    parallelly_1.36.0   \n [91] codetools_0.2-18     MASS_7.3-55          rprojroot_2.0.4     \n [94] withr_2.5.2          parallel_4.1.3       hms_1.1.3           \n [97] grid_4.1.3           rpart_4.1.16         timeDate_4032.109   \n[100] class_7.3-20         rmarkdown_2.25       ggforce_0.4.1       \n[103] lubridate_1.8.0"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html#eda---explorative-datenanalyse",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html#eda---explorative-datenanalyse",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Der Datensatz besteht aus 5593 Tweets, wovon kanpp 26% als Hate Speech klassifiziert wurden.\n\nggplot(d_hate, aes(x = \"\", y = \"\", fill = class)) +\n  geom_col() +\n  coord_polar(theta = \"y\") +\n   scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_void()\n\n\n\n\nWir können schon beim ersten Überfliegen des Datensatzes sehen, dass uns harter Tobak erwartet: Trans- & Homofeindlichkeit, Rassismus, Misogynie…\n“Why people think gay marriage is okay is beyond me.[…]” id 598 “Those n*****s disgust me. They should have dealt with 100 years ago, we wouldn’t be having these problems now.” id 2483\nAber dazu später mehr. Zuerst ein paar Grundlagen: Auch fällt auf, dass viele Usernames und URL’s inbegriffen sind. Diese sind vielleicht nicht relevant für unsere Analyse und sollten später evtl. aussortiert werden (starts_with(“http”, “@”))\n\n\nUm einzelne Wörter graphisch darstellbar zu machen, zerlegen wir die Tweets in ihre einzelnen Strings, also Wörter. Da sich die Funktion unnest_tokens() hier allerdings nicht so gut anstellt, benötigen wir einen eigenen Tokenizer. Dieser ist so angepasst, dass Usernamen und Links in den Tweets nicht aufgenommen werden.\n\ntxt &lt;- \"@BabyAnimalPics: baby monkey bathtime http://t.co/7KPWAdLF0R Awwwwe! This is soooo ADORABLE!\"\n\nstr_split(txt, \"[:space:]+\") %&gt;%\n    map(~ str_remove_all(.x, \"@[^ ]+|https?[:graph:]+|^[:punct:]+|[:punct:]+\"))\n\n[[1]]\n [1] \"\"         \"baby\"     \"monkey\"   \"bathtime\" \"\"         \"Awwwwe\"  \n [7] \"This\"     \"is\"       \"soooo\"    \"ADORABLE\"\n\n\nDazu müssen noch alle möglichen Zahlen entfernt werden wie z.B. Unicodes von auf Twitter genutzten Emojis oder Geldbeträge. Alles zu einer Funktion kombiniert, könnte wie folgt aussehen:\n\ntokenize_words &lt;- function(x, lowercase = TRUE) {\n  if (lowercase)\n    x &lt;- str_to_lower(x)\n  \n  str_split(x, \"[:space:]\") %&gt;%\n    map(~ str_remove_all(.x, \n          \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|^[:punct:]+|[:punct:]+|\\\\d+\")) %&gt;% \n    unlist()\n}\n\nMal probieren ob es klappt:\n\nd_hate_regtok &lt;-\n  d_hate %&gt;%\n    mutate(word = map(tweet, tokenize_words)) %&gt;% \n  unnest(cols = word)%&gt;% \n  select(-tweet) %&gt;% \n  filter(!word == \"\")\nhead(d_hate_regtok)\n\n\n\n  \n\n\n\nSchon besser!\n\n\n\nEs befinden sich noch einige Strings in der Liste, die keine (analysierbaren) Wörter darstellen. Da hilft nur eines: Stopwörter entfernen! Hierzu kombiniere ich einige gängige Listen und ergänze sie mit einer eigenen, auf den Datensatz zugeschnittene Liste (z.B. “rt” ist die Abkürzung von “retweet”, “yall” als umgangssprachliche Form von “you all”).\n\nsw_snowball &lt;- get_stopwords(source = \"snowball\")\nsw_iso &lt;- get_stopwords(source = \"stopwords-iso\")\nsw_smart &lt;- get_stopwords(source = \"smart\")\nsw_tweet &lt;- tibble(word = c(\"rt\", \"da\", \"yall\", \"ur\", \"yo\", \"dat\", \"smh\", \"tho\", \"ya\", \"bout\", \"em\", \"dis\", \"bc\", \"dem\", \"ima\", \"|\", \"dc\", \"$\", \"+\"))\nsw_combi &lt;- \n  bind_rows(sw_snowball, sw_iso, sw_smart, sw_tweet) %&gt;% \n  select(-lexicon)\n\nd_hate_tok_wstop &lt;- \n  d_hate_regtok %&gt;% \n  anti_join(sw_combi)\n\nJoining with `by = join_by(word)`\n\nhead(d_hate_tok_wstop)\n\n\n\n  \n\n\n\n\n\n\nNun, da die Tweets in ihre einzelnen Wörter aufgeteilt und bereinigt sind, können wir wunderbar visualisieren was der Datensatz bereithält.\nWelche Wörter kommen am häufigsten vor?\n\nd_hate_tok_wstop %&gt;%\n  count(word, sort = TRUE) %&gt;% \n  slice_max(order_by = n, n = 20) %&gt;% \n  mutate(word = factor(word)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, n), x = n) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nDas ganze nochmal, aber jetzt nach Klassifikation sortiert:\n\nlibrary(reshape2)\n\n\nAttache Paket: 'reshape2'\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    smiths\n\nd_hate_tok_wstop %&gt;% \n  count(word, class, sort = TRUE) %&gt;%\n  acast(word ~ class, value.var = \"n\", fill = 0) %&gt;%\n  comparison.cloud(colors = c(\"#D55E00\", \"#56B4E9\",\n                              title.bg.colors=\"white\"),\n                   max.words = 100)\n\n\n\n\n“Man sieht: Es sind Schimpfwörter im Haus!” Das könnte für die weitere Analyse/ Klassifikation interessantwerden, ebenso wie mögliche Codewörter wie “brownie” (Personen mit dunkler Hautfarbe) oder “birds” (Frauen).\n\n\n\nDie Sentimentanalyse erkennt und bewertet den überwiegende “Ton” oder die “Stimmung” eines Textes. Dieser Prozess kann auf einzelne Sätze, Absätze oder sogar auf gesamte Dokumente angewendet werden. Wir konzentrieren uns hier einmal auf einzelne Wörter mithilfe des Lexikons afinn und einmal auf die Bewertung im Kontext eines ganzen Satzes mit dem Paket sentimentr.\nMit afinn:\n\nAFINN &lt;- get_sentiments(lexicon = \"afinn\")\n\n\nd_hate_senti &lt;-\nd_hate_tok_wstop %&gt;% \n  inner_join(AFINN, by = \"word\")\n\n\nd_hate_senti %&gt;% \n  group_by(class) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% round(2))\n\n\n\n  \n\n\n\nEs gibt ungefähr gleich viele polarisierende Wörter auf Seiten der Hate Speech und der Übrigen. Jedoch sind die Wörter unter Hate Speech deutlich stärker emotional negativ aufgeladen.\n\nd_hate_senti %&gt;% \n  ggplot() +\n  geom_density(aes(value, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nMit sentimentr:\n\nhate_sentir &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  sentiment() %&gt;% \n  filter(!word_count == 0)\n\n\nhate_sentir %&gt;% \n  ggplot() +\n  geom_density(aes(sentiment, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nIm Vergleich zur Sentimenteinteilung von afinn sieht man hier eine ganz klare Spitze beim Wert der neutralen Bestandteile. Das liegt vor allem an der ungenauen Eintilung vom Befehl get_sentences(), der etliche Nicht-Sätze erstellt, die als neutral gewertet werden. Das könnte aber auch an der unterschiedlichen Herangehensweise, das Sentiment über die einzelnen Wörter bzw. im Kontext des gesamten Satzes zu ermitteln. Einzelne Wörter sind einfacher zu erkennen und eindeutiger zu bewerten.\nMit sentimentr kann man zusätzlich noch die Emotionen und Schimpfwörter analysieren.\n\nhate_emos &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion() %&gt;% \n  filter(!word_count == 0,\n         !emotion_count == 0)\n\n\nhate_emos %&gt;% \n  ggplot(aes(emotion_type, fill = class, colour = class)) +\n  geom_bar() +\n  scale_x_discrete(guide = guide_axis(angle = 60)) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDas ist ein sehr großer Datensatz, deshalb will ich für jede id/ jeden Tweet die dominante Emotion herausfinden und darauf basierend den Datensatz verschlanken.\n\nhate_emos2 &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion()\n\ndominant_emotion_df &lt;- \n  hate_emos2 %&gt;%\n  group_by(id, emotion_type) %&gt;%\n  summarize(weighted_score = sum(emotion_count * emotion)) %&gt;%\n  dplyr::slice(which.max(weighted_score)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\ndominant_emo_hate &lt;-\n  merge(d_hate, dominant_emotion_df, by = \"id\")\n\ndominant_emo_hate %&gt;% \n  ggplot(aes(class, emotion_type)) +\n  geom_bin2d() + \n  theme_minimal()\n\n\n\n\nKlappt!\nZwar muss bei dieser Grafik beachtet werden, dass der Anteil von other generell sehr viel größer ist, als der von hate speech und dementsprechend heller ist. Trotzdem kann man hier gut erkennen, welche Emotionen in den Tweets mit Hate Speech wohl vorherrscht: Wut, Ekel, Niedergeschlagenheit\nNun zu den Schimpfwörtern:\n\nhate_prof &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  profanity() %&gt;% \n  filter(!word_count == 0)\n\nKritik: Das Schimpfwortlexikon von sentimentr listet das N-Wort in manchen Schreibweisen nicht als Schimpfwort!\n\nhate_prof %&gt;% \n  ggplot(aes(element_id, profanity_count, fill = class)) +\n  geom_bin_2d() +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDie Tweets, die einen hohen Anteil an Schimpfwörtern haben, sind eher unter hate speech gefallen, als andere.\n\n\n\nWord Embeddings sind eine Methode, um Textdaten als Vektoren von Zahlen darzustellen, basierend auf einem großen Textkorpus. Anders als bei tf_idf wird dabei die semantische Bedeutung aus dem Kontext der Wörter erfasst und die Textinformationen auf einen sehr dichte Raum reduziert. Aus diesem Grund tachen sie auch hier auf. Außerdem können wir dadurch erkennen, in welchem Kontext unsere angeblichen Codewörter stehen, und beurteilen, ob sie hier in erster Linie als solche verwendet werden.\n\ntidy_hate &lt;-\n  d_hate_tok_wstop %&gt;% \n  add_count(word) %&gt;% \n  filter(n &gt;= 15) %&gt;% \n  select(-n)\n\n\nnested_hate &lt;-\n  tidy_hate %&gt;% \n  nest(words = c(word))\n\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x,  # Syntax ähnlich zu purrr::map()\n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n    safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\n\nhate_pmi &lt;- nested_hate %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;% \n  unnest(words) %&gt;% \n  unite(window_id, id, window_id) %&gt;% \n  pairwise_pmi(word, window_id)\n\nhate_pmi\n\n\n\n  \n\n\n\n\nhate_word_vectors &lt;- hate_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\n-&gt; Um zu entdecken, welche Wörter sich am nächsten stehen. Hier kommen die erwähnten Codewörter ins Spiel.\n\nnearest_neighbors &lt;- function(df, token) {\n  df %&gt;%\n    widely(\n      ~ {\n        y &lt;- .[rep(token, nrow(.)), ]\n        res &lt;- rowSums(. * y) / \n          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))\n        \n        matrix(res, ncol = 1, dimnames = list(x = names(res)))\n      },\n      sort = TRUE\n    )(item1, dimension, value) %&gt;%\n    select(-item2)\n}\n\nFür Bird:\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"bird\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#CC79A7\") +\n  theme_minimal()\n\n\n\n\nDie Worte mit dem höchsten Wert lassen sich plausibel erklären und scheinen nicht sehr viel mit einem möglichen frauenverachtenden Codewort zu tun zu haben.(play, Flappy Birds, Angry Birds, games)\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"brownie\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nHier beziehen sich die meisten Wörter auch auf das Gebäck, statt auf Menschen Bezug zu nehmen.\nUm nochmal sicher zu gehen, ob dieses Vorgehen auch verlässlich ist, probieren wir es mit einem offensichtlichen Begriff\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"nigga\")\n\n\n\n  \n\n\n\nDefinitiv im Kontext negativerer Wörter!\nUm diese Embeddings für das spätere Modell zugänglich zu machen folgen noch ein paar Schritte.\n\nword_matrix &lt;- tidy_hate %&gt;%\n  count(id, word) %&gt;%\n  cast_sparse(id, word, n) \n\nembedding_matrix &lt;- hate_word_vectors %&gt;%\n  cast_sparse(item1, dimension, value)\n\n#doc_matrix &lt;- word_matrix %*% embedding_matrix\n#dim(doc_matrix)\n\n\nprint(dim(word_matrix))\n\n[1] 5235  309\n\nprint(dim(embedding_matrix))\n\n[1] 307 100\n\n\n\ndiff_matrix &lt;- dim(word_matrix) != dim(embedding_matrix)\ndiff_matrix\n\n[1] TRUE TRUE\n\n\nAus irgendeinem Grund gibt es einen Unterschied in den Matrizen, sodass ich sie nicht verbinden kann. Schade!\n\n\n\nn-grams stellen eine weitere Möglichkeit der Textanalyse dar, um Muster, Zusammenhänge und Beziehungen zwischen aufeinanderfolgenden Wörtern zu analysieren. Bigramme sind eine Sequenz von zwei aufeinanderfolgenden Elementen oder - in unserem Fall - Wörtern in einem Text. Als kleine Ergänzung zu den mögliche Codewörtern unter Word-Embeddings möchte ich hier noch einmal herausfinden welche Wörter denn wirklich häufig zusammen verwendet werden.\n\nbigrams_hate &lt;-\n  d_hate %&gt;% \n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2)\n\n\nsw_erg &lt;- tibble(word = c(\"t.co\", \"128557\", \"128514\", \"ho\", \"8230\", \"9733\", \"https\", \"http\"))\nadded_sw &lt;- bind_rows(sw_combi, sw_erg)\n\n\nlibrary(igraph)\n\n(bigram_graph &lt;- bigrams_hate %&gt;% \n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %&gt;%\n        filter(!word1 %in% added_sw$word,\n               !word2 %in% added_sw$word) %&gt;%\n        count(word1, word2, sort = TRUE) %&gt;%\n        unite(\"bigram\", c(word1, word2), sep = \" \") %&gt;%\n        filter(n &gt; 10) %&gt;%\n        graph_from_data_frame()\n)\n\nIGRAPH ce4131e DN-- 44 28 -- \n+ attr: name (v/c)\n+ edges from ce4131e (vertex names):\n [1] white trash   -&gt;66 flappy bird   -&gt;40 charlie crist -&gt;34 charlie sheen -&gt;26\n [5] charlie brown -&gt;25 derek jeter   -&gt;24 ass nigga     -&gt;22 charlie baker -&gt;21\n [9] trash talk    -&gt;21 0221 24       -&gt;19 622 0221      -&gt;19 asian massage -&gt;19\n[13] park slope    -&gt;19 rated spa     -&gt;19 uncle tom     -&gt;19 128525 128525 -&gt;17\n[17] yankee stadium-&gt;17 happy birthday-&gt;16 bitch ass     -&gt;15 rick scott    -&gt;15\n[21] 718 622       -&gt;14 ice cream     -&gt;14 red sox       -&gt;13 white people  -&gt;13\n[25] colored folk  -&gt;12 black people  -&gt;11 fucking faggot-&gt;11 trash 8221    -&gt;11\n\n\n\nlibrary(ggraph)\nset.seed(42)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n        geom_edge_link() +\n        geom_node_point(color = \"#CC79A7\", size = 5) +\n        geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n        theme_void()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDas mit Abstand am häufigsten vorkommende Bigramm ist “white trash”, dicht gefolgt von “flappy bird”. Anscheinend mussten viele ihren Frust an der digitalen Tastatur auslassen, nachdem sie das Spiel gespielt haben… Rassistsche und beleidigende Äußerungen wie “uncle tom” und “fucking faggot” sind ebenfalls vertreten, sowie das Stadion der New York Yankees und deren erfolgreicher Spieler Derek Jeter."
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html#modellierung",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html#modellierung",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Jetzt soll es aber endlich um die Vorhersage von Hate Speech gehen. Zuerst bleiben wir noch in R und bauen ein Klassifizierungsmodell für Hate Speech in tidymodels.Danach geht es weiter in Python und wir nutzen ein Large Language Model (LLM) für eine Zero-Shot-Learning-Vorhersage, also ohne vorheriges Fine-Tuning des LLM.\n\n\n\nhate_for_rec &lt;-\n  d_hate %&gt;% \n  mutate(tweet = str_remove_all(tweet, \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|\\\\d+\"))\n\n\nset.seed(42)\nhate_split &lt;- initial_split(hate_for_rec, strata = class)\n\ntrain_hate &lt;- training(hate_split)\ntest_hate &lt;- testing(hate_split)\n\n\n\n\nWir brauchen noch folgende Listen vorab, da sich die Befehle von sentimentr schlecht in ein recipe einfügen lassen. Das im default verwendete Schimpfwort-Lexikon von sentimentr ergänze ich noch um ein anderes mit rassistischem Vokabular.\n\ndata(hash_sentiment_jockers_rinker)\nView(hash_sentiment_jockers_rinker)\nhash &lt;- hash_sentiment_jockers_rinker %&gt;% \n  rename(word = x,\n         value = y)\n\nprofal &lt;- unique(tolower(profanity_alvarez)) \ndata(\"profanity_racist\")\nprofanity &lt;- as_tibble(c(profal, profanity_racist))\nprofanity &lt;- profanity %&gt;% \n  rename(word = value) %&gt;% \n  mutate(value = 1)\n\n\nrec1 &lt;-\n  recipe(class ~ ., data = train_hate) %&gt;% \n  update_role(id, new_role = \"id\") %&gt;% \n  update_role(tweet, new_role = \"ignore\") %&gt;% \n  step_text_normalization(tweet) %&gt;% \n  step_mutate(senta = get_sentiment(tweet, method = \"afinn\"),\n              sentr = get_sentiment(tweet, method = \"custom\", lexicon = hash), \n              profan = get_sentiment(tweet, method = \"custom\", lexicon = profanity))%&gt;% \n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_stopwords(tweet, custom_stopword_source = \"sw_combi\") %&gt;% \n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;% \n  step_tfidf(tweet) %&gt;% \n  step_zv(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nbaked &lt;- bake(prep(rec1), new_data = NULL)\n\n\n\n\nmod1 &lt;-\n  boost_tree(mtry = tune(), \n            min_n = tune(), \n            trees = tune(),\n            tree_depth = tune(),\n            learn_rate = tune(),\n            loss_reduction = tune(),\n           mode = \"classification\") %&gt;% \n  set_engine(\"xgboost\", nthreads = 4)\n\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n\n\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(train_hate, v = 3, repeats = 2)\n\n\n\n\n\ntic()\nwf_tune &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl,\n    grid = 5, \n    seed = 42,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE, save_workflow = TRUE))\ntoc()\n\n723.02 sec elapsed\n\n\n\ntune::autoplot(wf_tune) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmetrics &lt;-\nwf_tune %&gt;% \n  collect_metrics() \nmetrics %&gt;% \n  arrange(-mean) %&gt;% \n  head()\n\n\n\n  \n\n\n\n-&gt; Preprocessor1_Model5 schneidet am besten ab.\n\n\n\n\nfinal_fit &lt;- \n  fit_best(wf_tune)\n\n[19:25:08] WARNING: amalgamation/../src/learner.cc:627: \nParameters: { \"nthreads\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nWelche Prädiktoren waren bei diesem Modell die wichtigsten?\n\nfinal_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 15, geom = \"point\") +\n  theme_minimal()\n\n\n\n\nWie schon in der EDA vermutet, nehmen Schimpfwörter einen sehr prominenten Wert in der Vorhersage ein. Zusammen mit den beiden Sentiment-Lexika und dem tf_idf-Wert für “white” führt es die Liste an.\n\n\n\n\npred_test &lt;- \n  final_fit %&gt;% \n  predict(new_data = test_hate) %&gt;% \n  bind_cols(test_hate)\n\n\npred_test1 &lt;-\n  pred_test %&gt;% \n  mutate(class = as_factor(class),\n         .pred_class = ifelse(.pred_class == \"hate speech\", 1, 0)) %&gt;% \n  mutate(class = ifelse(class == \"hate speech\", 1, 0))\n\nrocobj &lt;- \n  pred_test1 %&gt;% \n  roc(class, .pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#0072B2\", size = 1.5)\n\n\n\n\nObwohl unsere Vorhersage im Train-Sample eine accuracy von ca. 89% aufweist, liegt die ROC-Kurve für die Vorhersage auf das Test-Sample unter der Zufallslinie. Das bedeutet, dass unser Klassifikator schlechter ist, als zufällige Vorhersagen… Schade! Vielleicht ist es besser mit einem Transformer-Modell ;)"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html#transformer-modell",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html#transformer-modell",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Wir nutzen Transformer-Modelle über die Huggingface-API für unser Zero-Shot-Learning. Ich habe mich hier für das Modell entschieden, das im Bezug auf Hate-Speech-Detection im Internet am häufigsten heruntergeladen wurde und sich in den Suchvorschlägen ganz oben befindet.\n\n\n\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\n\ntweet &lt;- test_hate$tweet\n\n\nhate_py = r.tweet\n\n\n\n\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\nresult = classifier(hate_py)\n\n\n\n\n…um die Ergebnisse der Vorhersage des Transformer-Modells vergleichen zu können.\n\nr_results &lt;- py$result\nhead(r_results)\n\n[[1]]\n[[1]]$label\n[1] \"nothate\"\n\n[[1]]$score\n[1] 0.9998609\n\n\n[[2]]\n[[2]]$label\n[1] \"nothate\"\n\n[[2]]$score\n[1] 0.8565221\n\n\n[[3]]\n[[3]]$label\n[1] \"nothate\"\n\n[[3]]$score\n[1] 0.6914555\n\n\n[[4]]\n[[4]]$label\n[1] \"hate\"\n\n[[4]]$score\n[1] 0.9997545\n\n\n[[5]]\n[[5]]$label\n[1] \"nothate\"\n\n[[5]]$score\n[1] 0.998069\n\n\n[[6]]\n[[6]]$label\n[1] \"nothate\"\n\n[[6]]$score\n[1] 0.9973779\n\n\n\nlabel &lt;- map(r_results, ~.$label)\n\npred_hate_py &lt;- \n  bind_cols(pred_test1, pred_py = unlist(label))\n\npred_hate_py &lt;- \n  pred_hate_py %&gt;%\n  mutate(pred_py = case_when(pred_py == \"hate\" ~ \"hate speech\",\n                             pred_py == \"nothate\" ~ \"other\"))  %&gt;%\n  mutate(pred_py = ifelse(pred_py == \"hate speech\", 1, 0))\n\n\nrocobj &lt;- \n  pred_hate_py %&gt;% \n  roc(class, pred_py)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#E69F00\", size = 1.5)\n\n\n\n\nOk, diese Form der “Kurve” weist Ähnlichkeiten zu der Kurve meines eigenen Modells auf… Allerdings hat dieses Modell einen steileren Anstieg, was beseutet, dass der Klassifikator mit höherer Genauigkeit positive Vorhersagen trifft, bevor viele falsch positive Vorhersagen gemacht werden.\n\ndiff_pred &lt;- \n  pred_hate_py %&gt;%\n  group_by(class) %&gt;%\n  count(pred_py != .pred_class)\ndiff_pred\n\n\n\n  \n\n\n\nIm direkten Vergleich haben das Transformer-Modell von Huggingface und mein tidymodels-Modell 269 Werte verschieden bewertet. Unter Nicht-Hate Speech gab es etwas mehr Unstimmigkeiten als bei Hate Speech selbst."
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html#fazit",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html#fazit",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Die Klassifikation von Hate Speech in sozialen Netzwerken bleibt ein Buch mit vielen Siegeln. Eine nahezu perfekte Vorhersage, wird es wahrscheinlich in naher Zukunft nicht geben. Dafür gibt es zu viele Limitationen des Algorithmus. Nicht ohne Grund beschweren sich v.a. viele Comedians/ Internet-Clowns, dass ihre Accounts aufgrund von angeblicher Hassrede/ Hetze gesperrt werden, obwohl sie sich satirisch/ ironisch äußern. Auch die in diesem Blog schon mehrfach erwähnten Codewörter für Beleidigungen/ rassistische Bezeichnugnen werden nicht weniger. Das kann man am Beispiel von Chinas Staatsoberhaupt Xi veranschaulichen.\n“According to the censorship log leaked by the social media app Xiaohongshu in 2020, 564 words were considered “sensitive” by the Chinese government when referring to Xi.” Xiao H., 2023 (https://wagingnonviolence.org/2023/04/how-subvversive-nicknames-for-china-present-xi-jinping-fuel-dissent/; abgerufen am 09.02.24)\n… und es werden nicht weniger! Dennoch stellt dieser Blog einige Ansatzpunkte und verschiedene Möglichkeiten dar, die zumindest ein paar der Siegel öffnen können. Alles darüber hinaus wird die Zukunft bringen!"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.knit.html#quellen-weitere-informationen",
    "href": "posts/Pruefungsleistung/pruefungsleistung.knit.html#quellen-weitere-informationen",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Dieser Blogbeitrag orientiert sich an den Kursinhalten des Schwerpunktmoduls “Data Science 2” im Studiengang “Angewandte Wirtschafts- & Medienpsychologie”, betreut von Prof. Dr. habil. Sebastian Sauer.\nSebastian Sauer. (2023). sebastiansauer/datascience-text: v0.1.0 (Version draft1). Zenodo. https://doi.org/10.5281/zenodo.8279822.\n\n\n\nsessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28    stringi_1.7.6      ggraph_2.1.0       igraph_1.4.2      \n [5] reshape2_1.4.4     pROC_1.18.0        caret_6.0-94       lattice_0.20-45   \n [9] vip_0.4.1          tictoc_1.2         xgboost_1.6.0.1    lexicon_1.2.1     \n[13] syuzhet_1.0.7      tokenizers_0.3.0   textrecipes_1.0.3  furrr_0.3.1       \n[17] future_1.33.0      irlba_2.3.5.1      Matrix_1.5-4       widyr_0.1.5       \n[21] sentimentr_2.9.0   wordcloud_2.6      RColorBrewer_1.1-3 stopwords_2.3     \n[25] yardstick_1.1.0    workflowsets_1.0.1 workflows_1.1.3    tune_1.1.2        \n[29] rsample_1.2.0      recipes_1.0.9      parsnip_1.0.4      modeldata_1.2.0   \n[33] infer_1.0.5        dials_1.2.0        scales_1.2.1       broom_1.0.5       \n[37] tidymodels_1.0.0   see_0.8.1          report_0.5.7       parameters_0.21.0 \n[41] performance_0.10.3 modelbased_0.8.6   insight_0.19.2     effectsize_0.8.3  \n[45] datawizard_0.7.1   correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0   \n[49] tidytext_0.4.1     forcats_0.5.1      stringr_1.5.0      dplyr_1.1.2       \n[53] purrr_1.0.1        readr_2.1.2        tidyr_1.2.0        tibble_3.2.1      \n[57] ggplot2_3.4.4      tidyverse_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.3.1         backports_1.4.1      plyr_1.8.8          \n  [4] splines_4.1.3        listenv_0.9.0        SnowballC_0.7.0     \n  [7] digest_0.6.29        foreach_1.5.2        htmltools_0.5.5     \n [10] viridis_0.6.4        fansi_1.0.2          magrittr_2.0.2      \n [13] tzdb_0.3.0           graphlayouts_0.8.4   globals_0.16.2      \n [16] modelr_0.1.11        gower_1.0.1          vroom_1.6.1         \n [19] textshape_1.7.3      hardhat_1.3.0        colorspace_2.0-3    \n [22] ggrepel_0.9.3        rappdirs_0.3.3       rvest_1.0.3         \n [25] warp_0.2.0           haven_2.4.3          xfun_0.39           \n [28] crayon_1.5.2         jsonlite_1.8.4       survival_3.2-13     \n [31] iterators_1.0.14     glue_1.6.2           polyclip_1.10-4     \n [34] gtable_0.3.4         ipred_0.9-14         future.apply_1.11.0 \n [37] DBI_1.1.3            qdapRegex_0.7.8      Rcpp_1.0.8          \n [40] viridisLite_0.4.2    bit_4.0.5            GPfit_1.0-8         \n [43] textclean_0.9.3      stats4_4.1.3         lava_1.7.3          \n [46] prodlim_2023.03.31   htmlwidgets_1.6.2    httr_1.4.7          \n [49] ellipsis_0.3.2       farver_2.1.1         pkgconfig_2.0.3     \n [52] nnet_7.3-17          dbplyr_2.3.2         here_1.0.1          \n [55] utf8_1.2.2           labeling_0.4.3       tidyselect_1.2.0    \n [58] rlang_1.1.2          DiceDesign_1.9       munsell_0.5.0       \n [61] cellranger_1.1.0     tools_4.1.3          cli_3.6.0           \n [64] generics_0.1.3       evaluate_0.23        fastmap_1.1.0       \n [67] yaml_2.3.5           textdata_0.4.4       bit64_4.0.5         \n [70] ModelMetrics_1.2.2.2 knitr_1.37           fs_1.5.2            \n [73] tidygraph_1.2.3      nlme_3.1-155         xml2_1.3.3          \n [76] compiler_4.1.3       rstudioapi_0.15.0    png_0.1-8           \n [79] slider_0.3.0         reprex_2.0.2         tweenr_2.0.2        \n [82] lhs_1.1.6            vctrs_0.6.1          pillar_1.9.0        \n [85] lifecycle_1.0.4      data.table_1.14.8    R6_2.5.1            \n [88] gridExtra_2.3        janeaustenr_1.0.0    parallelly_1.36.0   \n [91] codetools_0.2-18     MASS_7.3-55          rprojroot_2.0.4     \n [94] withr_2.5.2          parallel_4.1.3       hms_1.1.3           \n [97] grid_4.1.3           rpart_4.1.16         timeDate_4032.109   \n[100] class_7.3-20         rmarkdown_2.25       ggforce_0.4.1       \n[103] lubridate_1.8.0"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "X, vormals Twitter, ist schon lange als Hexenkessel bzw. Sammelbecken für Internet-Trolle bekannt. Nirgendwo sonst im Internet wird so prominent polarisiert, getrollt oder beleidigt. Unter anderem deshalb bietet sich die Plattform an, um die Beiträge dr Mitglieder zu analysieren und Hassrede zu identifizieren. In diesem Beitrag soll eine Auswahl solcher Tweets genauer untersucht werden. Zuerst wird der Datensatz pr Explorative Datenanalyse dargestellt. Danach werden mehrere Klassifikationen nach Hate Speech vorgenommen mittels verschiedener Methoden des Text-Minings. Viel Vergnügen!\n\n\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.4.4     v purrr   1.0.1\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.5.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\nv bayestestR  0.13.1   v correlation 0.8.4 \nx datawizard  0.7.1    x effectsize  0.8.3 \nx insight     0.19.2   v modelbased  0.8.6 \nx performance 0.10.3   x parameters  0.21.0\nx report      0.5.7    v see         0.8.1 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\n\n-- Attaching packages -------------------------------------- tidymodels 1.0.0 --\n\n\nv broom        1.0.5     v rsample      1.2.0\nv dials        1.2.0     v tune         1.1.2\nv infer        1.0.5     v workflows    1.1.3\nv modeldata    1.2.0     v workflowsets 1.0.1\nv parsnip      1.0.4     v yardstick    1.1.0\nv recipes      1.0.9     \n\n\n-- Conflicts ----------------------------------------- tidymodels_conflicts() --\nx scales::discard()        masks purrr::discard()\nx dplyr::filter()          masks stats::filter()\nx recipes::fixed()         masks stringr::fixed()\nx yardstick::get_weights() masks insight::get_weights()\nx dplyr::lag()             masks stats::lag()\nx yardstick::mae()         masks performance::mae()\nx parsnip::null_model()    masks insight::null_model()\nx infer::p_value()         masks parameters::p_value()\nx tune::parameters()       masks dials::parameters(), parameters::parameters()\nx yardstick::rmse()        masks performance::rmse()\nx dials::smoothness()      masks datawizard::smoothness()\nx yardstick::spec()        masks readr::spec()\nx recipes::step()          masks stats::step()\n* Dig deeper into tidy modeling with R at https://www.tmwr.org\n\n\nLade nötiges Paket: RColorBrewer\n\n\nLade nötiges Paket: Matrix\n\n\n\nAttache Paket: 'Matrix'\n\n\nDie folgenden Objekte sind maskiert von 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLade nötiges Paket: future\n\n\n\nAttache Paket: 'syuzhet'\n\n\nDas folgende Objekt ist maskiert 'package:sentimentr':\n\n    get_sentences\n\n\nDas folgende Objekt ist maskiert 'package:scales':\n\n    rescale\n\n\nDas folgende Objekt ist maskiert 'package:datawizard':\n\n    rescale\n\n\n\nAttache Paket: 'lexicon'\n\n\nDas folgende Objekt ist maskiert 'package:sentimentr':\n\n    available_data\n\n\n\nAttache Paket: 'xgboost'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    slice\n\n\n\nAttache Paket: 'vip'\n\n\nDas folgende Objekt ist maskiert 'package:utils':\n\n    vi\n\n\nLade nötiges Paket: lattice\n\n\n\nAttache Paket: 'caret'\n\n\nDas folgende Objekt ist maskiert 'package:future':\n\n    cluster\n\n\nDie folgenden Objekte sind maskiert von 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nDas folgende Objekt ist maskiert 'package:parameters':\n\n    compare_models\n\n\nDas folgende Objekt ist maskiert 'package:purrr':\n\n    lift\n\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttache Paket: 'pROC'\n\n\nDas folgende Objekt ist maskiert 'package:parameters':\n\n    ci\n\n\nDie folgenden Objekte sind maskiert von 'package:bayestestR':\n\n    auc, ci\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    cov, smooth, var\n\n\n\n\nColor Palettes for Color Blindness: Okabe-Ito palette as suggested by Okabe & Ito (2008) (https://jfly.uni-koeln.de/color/) palette.colors(palette = “Okabe-Ito”) black orange skyblue bluishgreen yellow “#000000” “#E69F00” “#56B4E9” “#009E73” “#F0E442” blue vermillion reddishpurple gray “#0072B2” “#D55E00” “#CC79A7” “#999999”\n\n\n\n\n\n\nRows: 5593 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (2): tweet, class\ndbl (1): id\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRows: 5,593\nColumns: 3\n$ id    &lt;dbl&gt; 0, 40, 63, 66, 67, 70, 75, 85, 90, 111, 116, 119, 120, 121, 123,~\n$ tweet &lt;chr&gt; \"!!! RT @mayasolovely: As a woman you shouldn't complain about c~\n$ class &lt;chr&gt; \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"~\n\n\n\n\n\nDer Datensatz besteht aus 5593 Tweets, wovon kanpp 26% als Hate Speech klassifiziert wurden.\n\nggplot(d_hate, aes(x = \"\", y = \"\", fill = class)) +\n  geom_col() +\n  coord_polar(theta = \"y\") +\n   scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_void()\n\n\n\n\nWir können schon beim ersten Überfliegen des Datensatzes sehen, dass uns harter Tobak erwartet: Trans- & Homofeindlichkeit, Rassismus, Misogynie…\n“Why people think gay marriage is okay is beyond me.[…]” id 598 “Those n*****s disgust me. They should have dealt with 100 years ago, we wouldn’t be having these problems now.” id 2483\nAber dazu später mehr. Zuerst ein paar Grundlagen: Auch fällt auf, dass viele Usernames und URL’s inbegriffen sind. Diese sind vielleicht nicht relevant für unsere Analyse und sollten später evtl. aussortiert werden (starts_with(“http”, “@”))\n\n\nUm einzelne Wörter graphisch darstellbar zu machen, zerlegen wir die Tweets in ihre einzelnen Strings, also Wörter. Da sich die Funktion unnest_tokens() hier allerdings nicht so gut anstellt, benötigen wir einen eigenen Tokenizer. Dieser ist so angepasst, dass Usernamen und Links in den Tweets nicht aufgenommen werden.\n\ntxt &lt;- \"@BabyAnimalPics: baby monkey bathtime http://t.co/7KPWAdLF0R Awwwwe! This is soooo ADORABLE!\"\n\nstr_split(txt, \"[:space:]+\") %&gt;%\n    map(~ str_remove_all(.x, \"@[^ ]+|https?[:graph:]+|^[:punct:]+|[:punct:]+\"))\n\n[[1]]\n [1] \"\"         \"baby\"     \"monkey\"   \"bathtime\" \"\"         \"Awwwwe\"  \n [7] \"This\"     \"is\"       \"soooo\"    \"ADORABLE\"\n\n\nDazu müssen noch alle möglichen Zahlen entfernt werden wie z.B. Unicodes von auf Twitter genutzten Emojis oder Geldbeträge. Alles zu einer Funktion kombiniert, könnte wie folgt aussehen:\n\ntokenize_words &lt;- function(x, lowercase = TRUE) {\n  if (lowercase)\n    x &lt;- str_to_lower(x)\n  \n  str_split(x, \"[:space:]\") %&gt;%\n    map(~ str_remove_all(.x, \n          \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|^[:punct:]+|[:punct:]+|\\\\d+\")) %&gt;% \n    unlist()\n}\n\nMal probieren ob es klappt:\n\nd_hate_regtok &lt;-\n  d_hate %&gt;%\n    mutate(word = map(tweet, tokenize_words)) %&gt;% \n  unnest(cols = word)%&gt;% \n  select(-tweet) %&gt;% \n  filter(!word == \"\")\nhead(d_hate_regtok)\n\n\n\n  \n\n\n\nSchon besser!\n\n\n\nEs befinden sich noch einige Strings in der Liste, die keine (analysierbaren) Wörter darstellen. Da hilft nur eines: Stopwörter entfernen! Hierzu kombiniere ich einige gängige Listen und ergänze sie mit einer eigenen, auf den Datensatz zugeschnittene Liste (z.B. “rt” ist die Abkürzung von “retweet”, “yall” als umgangssprachliche Form von “you all”).\n\nsw_snowball &lt;- get_stopwords(source = \"snowball\")\nsw_iso &lt;- get_stopwords(source = \"stopwords-iso\")\nsw_smart &lt;- get_stopwords(source = \"smart\")\nsw_tweet &lt;- tibble(word = c(\"rt\", \"da\", \"yall\", \"ur\", \"yo\", \"dat\", \"smh\", \"tho\", \"ya\", \"bout\", \"em\", \"dis\", \"bc\", \"dem\", \"ima\", \"|\", \"dc\", \"$\", \"+\"))\nsw_combi &lt;- \n  bind_rows(sw_snowball, sw_iso, sw_smart, sw_tweet) %&gt;% \n  select(-lexicon)\n\nd_hate_tok_wstop &lt;- \n  d_hate_regtok %&gt;% \n  anti_join(sw_combi)\n\nJoining with `by = join_by(word)`\n\nhead(d_hate_tok_wstop)\n\n\n\n  \n\n\n\n\n\n\nNun, da die Tweets in ihre einzelnen Wörter aufgeteilt und bereinigt sind, können wir wunderbar visualisieren was der Datensatz bereithält.\nWelche Wörter kommen am häufigsten vor?\n\nd_hate_tok_wstop %&gt;%\n  count(word, sort = TRUE) %&gt;% \n  slice_max(order_by = n, n = 20) %&gt;% \n  mutate(word = factor(word)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, n), x = n) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nDas ganze nochmal, aber jetzt nach Klassifikation sortiert:\n\nlibrary(reshape2)\n\n\nAttache Paket: 'reshape2'\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    smiths\n\nd_hate_tok_wstop %&gt;% \n  count(word, class, sort = TRUE) %&gt;%\n  acast(word ~ class, value.var = \"n\", fill = 0) %&gt;%\n  comparison.cloud(colors = c(\"#D55E00\", \"#56B4E9\",\n                              title.bg.colors=\"white\"),\n                   max.words = 100)\n\n\n\n\n“Man sieht: Es sind Schimpfwörter im Haus!” Das könnte für die weitere Analyse/ Klassifikation interessantwerden, ebenso wie mögliche Codewörter wie “brownie” (Personen mit dunkler Hautfarbe) oder “birds” (Frauen).\n\n\n\nDie Sentimentanalyse erkennt und bewertet den überwiegende “Ton” oder die “Stimmung” eines Textes. Dieser Prozess kann auf einzelne Sätze, Absätze oder sogar auf gesamte Dokumente angewendet werden. Wir konzentrieren uns hier einmal auf einzelne Wörter mithilfe des Lexikons afinn und einmal auf die Bewertung im Kontext eines ganzen Satzes mit dem Paket sentimentr.\nMit afinn:\n\nAFINN &lt;- get_sentiments(lexicon = \"afinn\")\n\n\nd_hate_senti &lt;-\nd_hate_tok_wstop %&gt;% \n  inner_join(AFINN, by = \"word\")\n\n\nd_hate_senti %&gt;% \n  group_by(class) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% round(2))\n\n\n\n  \n\n\n\nEs gibt ungefähr gleich viele polarisierende Wörter auf Seiten der Hate Speech und der Übrigen. Jedoch sind die Wörter unter Hate Speech deutlich stärker emotional negativ aufgeladen.\n\nd_hate_senti %&gt;% \n  ggplot() +\n  geom_density(aes(value, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nMit sentimentr:\n\nhate_sentir &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  sentiment() %&gt;% \n  filter(!word_count == 0)\n\n\nhate_sentir %&gt;% \n  ggplot() +\n  geom_density(aes(sentiment, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nIm Vergleich zur Sentimenteinteilung von afinn sieht man hier eine ganz klare Spitze beim Wert der neutralen Bestandteile. Das liegt vor allem an der ungenauen Eintilung vom Befehl get_sentences(), der etliche Nicht-Sätze erstellt, die als neutral gewertet werden. Das könnte aber auch an der unterschiedlichen Herangehensweise, das Sentiment über die einzelnen Wörter bzw. im Kontext des gesamten Satzes zu ermitteln. Einzelne Wörter sind einfacher zu erkennen und eindeutiger zu bewerten.\nMit sentimentr kann man zusätzlich noch die Emotionen und Schimpfwörter analysieren.\n\nhate_emos &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion() %&gt;% \n  filter(!word_count == 0,\n         !emotion_count == 0)\n\n\nhate_emos %&gt;% \n  ggplot(aes(emotion_type, fill = class, colour = class)) +\n  geom_bar() +\n  scale_x_discrete(guide = guide_axis(angle = 60)) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDas ist ein sehr großer Datensatz, deshalb will ich für jede id/ jeden Tweet die dominante Emotion herausfinden und darauf basierend den Datensatz verschlanken.\n\nhate_emos2 &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion()\n\ndominant_emotion_df &lt;- \n  hate_emos2 %&gt;%\n  group_by(id, emotion_type) %&gt;%\n  summarize(weighted_score = sum(emotion_count * emotion)) %&gt;%\n  dplyr::slice(which.max(weighted_score)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\ndominant_emo_hate &lt;-\n  merge(d_hate, dominant_emotion_df, by = \"id\")\n\ndominant_emo_hate %&gt;% \n  ggplot(aes(class, emotion_type)) +\n  geom_bin2d() + \n  theme_minimal()\n\n\n\n\nKlappt!\nZwar muss bei dieser Grafik beachtet werden, dass der Anteil von other generell sehr viel größer ist, als der von hate speech und dementsprechend heller ist. Trotzdem kann man hier gut erkennen, welche Emotionen in den Tweets mit Hate Speech wohl vorherrscht: Wut, Ekel, Niedergeschlagenheit\nNun zu den Schimpfwörtern:\n\nhate_prof &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  profanity() %&gt;% \n  filter(!word_count == 0)\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\n\nKritik: Das Schimpfwortlexikon von sentimentr listet das N-Wort in manchen Schreibweisen nicht als Schimpfwort!\n\nhate_prof %&gt;% \n  ggplot(aes(element_id, profanity_count, fill = class)) +\n  geom_bin_2d() +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDie Tweets, die einen hohen Anteil an Schimpfwörtern haben, sind eher unter hate speech gefallen, als andere.\n\n\n\nWord Embeddings sind eine Methode, um Textdaten als Vektoren von Zahlen darzustellen, basierend auf einem großen Textkorpus. Anders als bei tf_idf wird dabei die semantische Bedeutung aus dem Kontext der Wörter erfasst und die Textinformationen auf einen sehr dichte Raum reduziert. Aus diesem Grund tachen sie auch hier auf. Außerdem können wir dadurch erkennen, in welchem Kontext unsere angeblichen Codewörter stehen, und beurteilen, ob sie hier in erster Linie als solche verwendet werden.\n\ntidy_hate &lt;-\n  d_hate_tok_wstop %&gt;% \n  add_count(word) %&gt;% \n  filter(n &gt;= 15) %&gt;% \n  select(-n)\n\n\nnested_hate &lt;-\n  tidy_hate %&gt;% \n  nest(words = c(word))\n\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x,  # Syntax ähnlich zu purrr::map()\n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n    safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\n\nhate_pmi &lt;- nested_hate %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;% \n  unnest(words) %&gt;% \n  unite(window_id, id, window_id) %&gt;% \n  pairwise_pmi(word, window_id)\n\nhate_pmi\n\n\n\n  \n\n\n\n\nhate_word_vectors &lt;- hate_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\n-&gt; Um zu entdecken, welche Wörter sich am nächsten stehen. Hier kommen die erwähnten Codewörter ins Spiel.\n\nnearest_neighbors &lt;- function(df, token) {\n  df %&gt;%\n    widely(\n      ~ {\n        y &lt;- .[rep(token, nrow(.)), ]\n        res &lt;- rowSums(. * y) / \n          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))\n        \n        matrix(res, ncol = 1, dimnames = list(x = names(res)))\n      },\n      sort = TRUE\n    )(item1, dimension, value) %&gt;%\n    select(-item2)\n}\n\nFür Bird:\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"bird\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#CC79A7\") +\n  theme_minimal()\n\n\n\n\nDie Worte mit dem höchsten Wert lassen sich plausibel erklären und scheinen nicht sehr viel mit einem möglichen frauenverachtenden Codewort zu tun zu haben.(play, Flappy Birds, Angry Birds, games)\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"brownie\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nHier beziehen sich die meisten Wörter auch auf das Gebäck, statt auf Menschen Bezug zu nehmen.\nUm nochmal sicher zu gehen, ob dieses Vorgehen auch verlässlich ist, probieren wir es mit einem offensichtlichen Begriff\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"nigga\")\n\n\n\n  \n\n\n\nDefinitiv im Kontext negativerer Wörter!\nUm diese Embeddings für das spätere Modell zugänglich zu machen folgen noch ein paar Schritte.\n\nword_matrix &lt;- tidy_hate %&gt;%\n  count(id, word) %&gt;%\n  cast_sparse(id, word, n) \n\nembedding_matrix &lt;- hate_word_vectors %&gt;%\n  cast_sparse(item1, dimension, value)\n\n#doc_matrix &lt;- word_matrix %*% embedding_matrix\n#dim(doc_matrix)\n\n\nprint(dim(word_matrix))\n\n[1] 5235  309\n\nprint(dim(embedding_matrix))\n\n[1] 307 100\n\n\n\ndiff_matrix &lt;- dim(word_matrix) != dim(embedding_matrix)\ndiff_matrix\n\n[1] TRUE TRUE\n\n\nAus irgendeinem Grund gibt es einen Unterschied in den Matrizen, sodass ich sie nicht verbinden kann. Schade!\n\n\n\nn-grams stellen eine weitere Möglichkeit der Textanalyse dar, um Muster, Zusammenhänge und Beziehungen zwischen aufeinanderfolgenden Wörtern zu analysieren. Bigramme sind eine Sequenz von zwei aufeinanderfolgenden Elementen oder - in unserem Fall - Wörtern in einem Text. Als kleine Ergänzung zu den mögliche Codewörtern unter Word-Embeddings möchte ich hier noch einmal herausfinden welche Wörter denn wirklich häufig zusammen verwendet werden.\n\nbigrams_hate &lt;-\n  d_hate %&gt;% \n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2)\n\n\nsw_erg &lt;- tibble(word = c(\"t.co\", \"128557\", \"128514\", \"ho\", \"8230\", \"9733\", \"https\", \"http\"))\nadded_sw &lt;- bind_rows(sw_combi, sw_erg)\n\n\nlibrary(igraph)\n\n\nAttache Paket: 'igraph'\n\n\nDie folgenden Objekte sind maskiert von 'package:future':\n\n    %-&gt;%, %&lt;-%\n\n\nDie folgenden Objekte sind maskiert von 'package:dials':\n\n    degree, neighbors\n\n\nDas folgende Objekt ist maskiert 'package:datawizard':\n\n    normalize\n\n\nDie folgenden Objekte sind maskiert von 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nDie folgenden Objekte sind maskiert von 'package:purrr':\n\n    compose, simplify\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    crossing\n\n\nDas folgende Objekt ist maskiert 'package:tibble':\n\n    as_data_frame\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    decompose, spectrum\n\n\nDas folgende Objekt ist maskiert 'package:base':\n\n    union\n\n(bigram_graph &lt;- bigrams_hate %&gt;% \n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %&gt;%\n        filter(!word1 %in% added_sw$word,\n               !word2 %in% added_sw$word) %&gt;%\n        count(word1, word2, sort = TRUE) %&gt;%\n        unite(\"bigram\", c(word1, word2), sep = \" \") %&gt;%\n        filter(n &gt; 10) %&gt;%\n        graph_from_data_frame()\n)\n\nIGRAPH 9180658 DN-- 44 28 -- \n+ attr: name (v/c)\n+ edges from 9180658 (vertex names):\n [1] white trash   -&gt;66 flappy bird   -&gt;40 charlie crist -&gt;34 charlie sheen -&gt;26\n [5] charlie brown -&gt;25 derek jeter   -&gt;24 ass nigga     -&gt;22 charlie baker -&gt;21\n [9] trash talk    -&gt;21 0221 24       -&gt;19 622 0221      -&gt;19 asian massage -&gt;19\n[13] park slope    -&gt;19 rated spa     -&gt;19 uncle tom     -&gt;19 128525 128525 -&gt;17\n[17] yankee stadium-&gt;17 happy birthday-&gt;16 bitch ass     -&gt;15 rick scott    -&gt;15\n[21] 718 622       -&gt;14 ice cream     -&gt;14 red sox       -&gt;13 white people  -&gt;13\n[25] colored folk  -&gt;12 black people  -&gt;11 fucking faggot-&gt;11 trash 8221    -&gt;11\n\n\n\nlibrary(ggraph)\nset.seed(42)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n        geom_edge_link() +\n        geom_node_point(color = \"#CC79A7\", size = 5) +\n        geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n        theme_void()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDas mit Abstand am häufigsten vorkommende Bigramm ist “white trash”, dicht gefolgt von “flappy bird”. Anscheinend mussten viele ihren Frust an der digitalen Tastatur auslassen, nachdem sie das Spiel gespielt haben… Rassistsche und beleidigende Äußerungen wie “uncle tom” und “fucking faggot” sind ebenfalls vertreten, sowie das Stadion der New York Yankees und deren erfolgreicher Spieler Derek Jeter.\n\n\n\n\nJetzt soll es aber endlich um die Vorhersage von Hate Speech gehen. Zuerst bleiben wir noch in R und bauen ein Klassifizierungsmodell für Hate Speech in tidymodels.Danach geht es weiter in Python und wir nutzen ein Large Language Model (LLM) für eine Zero-Shot-Learning-Vorhersage, also ohne vorheriges Fine-Tuning des LLM.\n\n\n\nhate_for_rec &lt;-\n  d_hate %&gt;% \n  mutate(tweet = str_remove_all(tweet, \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|\\\\d+\"))\n\n\nset.seed(42)\nhate_split &lt;- initial_split(hate_for_rec, strata = class)\n\ntrain_hate &lt;- training(hate_split)\ntest_hate &lt;- testing(hate_split)\n\n\n\n\nWir brauchen noch folgende Listen vorab, da sich die Befehle von sentimentr schlecht in ein recipe einfügen lassen. Das im default verwendete Schimpfwort-Lexikon von sentimentr ergänze ich noch um ein anderes mit rassistischem Vokabular.\n\ndata(hash_sentiment_jockers_rinker)\nView(hash_sentiment_jockers_rinker)\nhash &lt;- hash_sentiment_jockers_rinker %&gt;% \n  rename(word = x,\n         value = y)\n\nprofal &lt;- unique(tolower(profanity_alvarez)) \ndata(\"profanity_racist\")\nprofanity &lt;- as_tibble(c(profal, profanity_racist))\nprofanity &lt;- profanity %&gt;% \n  rename(word = value) %&gt;% \n  mutate(value = 1)\n\n\nrec1 &lt;-\n  recipe(class ~ ., data = train_hate) %&gt;% \n  update_role(id, new_role = \"id\") %&gt;% \n  update_role(tweet, new_role = \"ignore\") %&gt;% \n  step_text_normalization(tweet) %&gt;% \n  step_mutate(senta = get_sentiment(tweet, method = \"afinn\"),\n              sentr = get_sentiment(tweet, method = \"custom\", lexicon = hash), \n              profan = get_sentiment(tweet, method = \"custom\", lexicon = profanity))%&gt;% \n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_stopwords(tweet, custom_stopword_source = \"sw_combi\") %&gt;% \n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;% \n  step_tfidf(tweet) %&gt;% \n  step_zv(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nbaked &lt;- bake(prep(rec1), new_data = NULL)\n\n\n\n\nmod1 &lt;-\n  boost_tree(mtry = tune(), \n            min_n = tune(), \n            trees = tune(),\n            tree_depth = tune(),\n            learn_rate = tune(),\n            loss_reduction = tune(),\n           mode = \"classification\") %&gt;% \n  set_engine(\"xgboost\", nthreads = 4)\n\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n\n\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(train_hate, v = 3, repeats = 2)\n\n\n\n\n\ntic()\nwf_tune &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl,\n    grid = 5, \n    seed = 42,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE, save_workflow = TRUE))\n\nWarning: The `...` are not used in this function but one or more objects were\npassed: 'seed'\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\ni Fold1, Repeat1: preprocessor 1/1\n\n\nv Fold1, Repeat1: preprocessor 1/1\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1\n\n\nv Fold2, Repeat1: preprocessor 1/1\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1\n\n\nv Fold3, Repeat1: preprocessor 1/1\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1\n\n\nv Fold1, Repeat2: preprocessor 1/1\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1\n\n\nv Fold2, Repeat2: preprocessor 1/1\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1\n\n\nv Fold3, Repeat2: preprocessor 1/1\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\ntoc()\n\n552.01 sec elapsed\n\n\n\ntune::autoplot(wf_tune) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmetrics &lt;-\nwf_tune %&gt;% \n  collect_metrics() \nmetrics %&gt;% \n  arrange(-mean) %&gt;% \n  head()\n\n\n\n  \n\n\n\n-&gt; Preprocessor1_Model5 schneidet am besten ab.\n\n\n\n\nfinal_fit &lt;- \n  fit_best(wf_tune)\n\n[18:44:41] WARNING: amalgamation/../src/learner.cc:627: \nParameters: { \"nthreads\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nWelche Prädiktoren waren bei diesem Modell die wichtigsten?\n\nfinal_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 15, geom = \"point\") +\n  theme_minimal()\n\n\n\n\nWie schon in der EDA vermutet, nehmen Schimpfwörter einen sehr prominenten Wert in der Vorhersage ein. Zusammen mit den beiden Sentiment-Lexika und dem tf_idf-Wert für “white” führt es die Liste an.\n\n\n\n\npred_test &lt;- \n  final_fit %&gt;% \n  predict(new_data = test_hate) %&gt;% \n  bind_cols(test_hate)\n\n\npred_test1 &lt;-\n  pred_test %&gt;% \n  mutate(class = as_factor(class),\n         .pred_class = ifelse(.pred_class == \"hate speech\", 1, 0)) %&gt;% \n  mutate(class = ifelse(class == \"hate speech\", 1, 0))\n\nrocobj &lt;- \n  pred_test1 %&gt;% \n  roc(class, .pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#0072B2\", size = 1.5)\n\n\n\n\nObwohl unsere Vorhersage im Train-Sample eine accuracy von ca. 89% aufweist, liegt die ROC-Kurve für die Vorhersage auf das Test-Sample unter der Zufallslinie. Das bedeutet, dass unser Klassifikator schlechter ist, als zufällige Vorhersagen… Schade! Vielleicht ist es besser mit einem Transformer-Modell ;)\n\n\n\n\nWir nutzen Transformer-Modelle über die Huggingface-API für unser Zero-Shot-Learning. Ich habe mich hier für das Modell entschieden, das im Bezug auf Hate-Speech-Detection im Internet am häufigsten heruntergeladen wurde und sich in den Suchvorschlägen ganz oben befindet.\n\n\n\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\n\ntweet &lt;- test_hate$tweet\n\n\nhate_py = r.tweet\n\n\n\n\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\nresult = classifier(hate_py)\n\n\n\n\n…um die Ergebnisse der Vorhersage des Transformer-Modells vergleichen zu können.\n\nr_results &lt;- py$result\nhead(r_results)\n\n[[1]]\n[[1]]$label\n[1] \"nothate\"\n\n[[1]]$score\n[1] 0.9998609\n\n\n[[2]]\n[[2]]$label\n[1] \"nothate\"\n\n[[2]]$score\n[1] 0.8565221\n\n\n[[3]]\n[[3]]$label\n[1] \"nothate\"\n\n[[3]]$score\n[1] 0.6914555\n\n\n[[4]]\n[[4]]$label\n[1] \"hate\"\n\n[[4]]$score\n[1] 0.9997545\n\n\n[[5]]\n[[5]]$label\n[1] \"nothate\"\n\n[[5]]$score\n[1] 0.998069\n\n\n[[6]]\n[[6]]$label\n[1] \"nothate\"\n\n[[6]]$score\n[1] 0.9973779\n\n\n\nlabel &lt;- map(r_results, ~.$label)\n\npred_hate_py &lt;- \n  bind_cols(pred_test1, pred_py = unlist(label))\n\npred_hate_py &lt;- \n  pred_hate_py %&gt;%\n  mutate(pred_py = case_when(pred_py == \"hate\" ~ \"hate speech\",\n                             pred_py == \"nothate\" ~ \"other\"))  %&gt;%\n  mutate(pred_py = ifelse(pred_py == \"hate speech\", 1, 0))\n\n\nrocobj &lt;- \n  pred_hate_py %&gt;% \n  roc(class, pred_py)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#E69F00\", size = 1.5)\n\n\n\n\nOk, diese Form der “Kurve” weist Ähnlichkeiten zu der Kurve meines eigenen Modells auf… Allerdings hat dieses Modell einen steileren Anstieg, was beseutet, dass der Klassifikator mit höherer Genauigkeit positive Vorhersagen trifft, bevor viele falsch positive Vorhersagen gemacht werden.\n\ndiff_pred &lt;- \n  pred_hate_py %&gt;%\n  group_by(class) %&gt;%\n  count(pred_py != .pred_class)\ndiff_pred\n\n\n\n  \n\n\n\nIm direkten Vergleich haben das Transformer-Modell von Huggingface und mein tidymodels-Modell 269 Werte verschieden bewertet. Unter Nicht-Hate Speech gab es etwas mehr Unstimmigkeiten als bei Hate Speech selbst.\n\n\n\n\nDie Klassifikation von Hate Speech in sozialen Netzwerken bleibt ein Buch mit vielen Siegeln. Eine nahezu perfekte Vorhersage, wird es wahrscheinlich in naher Zukunft nicht geben. Dafür gibt es zu viele Limitationen des Algorithmus. Nicht ohne Grund beschweren sich v.a. viele Comedians/ Internet-Clowns, dass ihre Accounts aufgrund von angeblicher Hassrede/ Hetze gesperrt werden, obwohl sie sich satirisch/ ironisch äußern. Auch die in diesem Blog schon mehrfach erwähnten Codewörter für Beleidigungen/ rassistische Bezeichnugnen werden nicht weniger. Das kann man am Beispiel von Chinas Staatsoberhaupt Xi veranschaulichen.\n“According to the censorship log leaked by the social media app Xiaohongshu in 2020, 564 words were considered “sensitive” by the Chinese government when referring to Xi.” Xiao H., 2023 (https://wagingnonviolence.org/2023/04/how-subvversive-nicknames-for-china-present-xi-jinping-fuel-dissent/; abgerufen am 09.02.24)\n… und es werden nicht weniger! Dennoch stellt dieser Blog einige Ansatzpunkte und verschiedene Möglichkeiten dar, die zumindest ein paar der Siegel öffnen können. Alles darüber hinaus wird die Zukunft bringen!\n\n\n\nDieser Blogbeitrag orientiert sich an den Kursinhalten des Schwerpunktmoduls “Data Science 2” im Studiengang “Angewandte Wirtschafts- & Medienpsychologie”, betreut von Prof. Dr. habil. Sebastian Sauer.\nSebastian Sauer. (2023). sebastiansauer/datascience-text: v0.1.0 (Version draft1). Zenodo. https://doi.org/10.5281/zenodo.8279822.\n\n\n\nsessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28    stringi_1.7.6      ggraph_2.1.0       igraph_1.4.2      \n [5] reshape2_1.4.4     pROC_1.18.0        caret_6.0-94       lattice_0.20-45   \n [9] vip_0.4.1          tictoc_1.2         xgboost_1.6.0.1    lexicon_1.2.1     \n[13] syuzhet_1.0.7      tokenizers_0.3.0   textrecipes_1.0.3  furrr_0.3.1       \n[17] future_1.33.0      irlba_2.3.5.1      Matrix_1.5-4       widyr_0.1.5       \n[21] sentimentr_2.9.0   wordcloud_2.6      RColorBrewer_1.1-3 stopwords_2.3     \n[25] yardstick_1.1.0    workflowsets_1.0.1 workflows_1.1.3    tune_1.1.2        \n[29] rsample_1.2.0      recipes_1.0.9      parsnip_1.0.4      modeldata_1.2.0   \n[33] infer_1.0.5        dials_1.2.0        scales_1.2.1       broom_1.0.5       \n[37] tidymodels_1.0.0   see_0.8.1          report_0.5.7       parameters_0.21.0 \n[41] performance_0.10.3 modelbased_0.8.6   insight_0.19.2     effectsize_0.8.3  \n[45] datawizard_0.7.1   correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0   \n[49] tidytext_0.4.1     forcats_0.5.1      stringr_1.5.0      dplyr_1.1.2       \n[53] purrr_1.0.1        readr_2.1.2        tidyr_1.2.0        tibble_3.2.1      \n[57] ggplot2_3.4.4      tidyverse_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.3.1         backports_1.4.1      plyr_1.8.8          \n  [4] splines_4.1.3        listenv_0.9.0        SnowballC_0.7.0     \n  [7] digest_0.6.29        foreach_1.5.2        htmltools_0.5.5     \n [10] viridis_0.6.4        fansi_1.0.2          magrittr_2.0.2      \n [13] tzdb_0.3.0           graphlayouts_0.8.4   globals_0.16.2      \n [16] modelr_0.1.11        gower_1.0.1          vroom_1.6.1         \n [19] textshape_1.7.3      hardhat_1.3.0        colorspace_2.0-3    \n [22] ggrepel_0.9.3        rappdirs_0.3.3       rvest_1.0.3         \n [25] warp_0.2.0           haven_2.4.3          xfun_0.39           \n [28] crayon_1.5.2         jsonlite_1.8.4       survival_3.2-13     \n [31] iterators_1.0.14     glue_1.6.2           polyclip_1.10-4     \n [34] gtable_0.3.4         ipred_0.9-14         future.apply_1.11.0 \n [37] DBI_1.1.3            qdapRegex_0.7.8      Rcpp_1.0.8          \n [40] viridisLite_0.4.2    bit_4.0.5            GPfit_1.0-8         \n [43] textclean_0.9.3      stats4_4.1.3         lava_1.7.3          \n [46] prodlim_2023.03.31   htmlwidgets_1.6.2    httr_1.4.7          \n [49] ellipsis_0.3.2       farver_2.1.1         pkgconfig_2.0.3     \n [52] nnet_7.3-17          dbplyr_2.3.2         here_1.0.1          \n [55] utf8_1.2.2           labeling_0.4.3       tidyselect_1.2.0    \n [58] rlang_1.1.2          DiceDesign_1.9       munsell_0.5.0       \n [61] cellranger_1.1.0     tools_4.1.3          cli_3.6.0           \n [64] generics_0.1.3       evaluate_0.23        fastmap_1.1.0       \n [67] yaml_2.3.5           textdata_0.4.4       bit64_4.0.5         \n [70] ModelMetrics_1.2.2.2 knitr_1.37           fs_1.5.2            \n [73] tidygraph_1.2.3      nlme_3.1-155         xml2_1.3.3          \n [76] compiler_4.1.3       rstudioapi_0.15.0    png_0.1-8           \n [79] slider_0.3.0         reprex_2.0.2         tweenr_2.0.2        \n [82] lhs_1.1.6            vctrs_0.6.1          pillar_1.9.0        \n [85] lifecycle_1.0.4      data.table_1.14.8    R6_2.5.1            \n [88] gridExtra_2.3        janeaustenr_1.0.0    parallelly_1.36.0   \n [91] codetools_0.2-18     MASS_7.3-55          rprojroot_2.0.4     \n [94] withr_2.5.2          parallel_4.1.3       hms_1.1.3           \n [97] grid_4.1.3           rpart_4.1.16         timeDate_4032.109   \n[100] class_7.3-20         rmarkdown_2.25       ggforce_0.4.1       \n[103] lubridate_1.8.0"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html#eda---explorative-datenanalyse",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html#eda---explorative-datenanalyse",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Der Datensatz besteht aus 5593 Tweets, wovon kanpp 26% als Hate Speech klassifiziert wurden.\n\nggplot(d_hate, aes(x = \"\", y = \"\", fill = class)) +\n  geom_col() +\n  coord_polar(theta = \"y\") +\n   scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_void()\n\n\n\n\nWir können schon beim ersten Überfliegen des Datensatzes sehen, dass uns harter Tobak erwartet: Trans- & Homofeindlichkeit, Rassismus, Misogynie…\n“Why people think gay marriage is okay is beyond me.[…]” id 598 “Those n*****s disgust me. They should have dealt with 100 years ago, we wouldn’t be having these problems now.” id 2483\nAber dazu später mehr. Zuerst ein paar Grundlagen: Auch fällt auf, dass viele Usernames und URL’s inbegriffen sind. Diese sind vielleicht nicht relevant für unsere Analyse und sollten später evtl. aussortiert werden (starts_with(“http”, “@”))\n\n\nUm einzelne Wörter graphisch darstellbar zu machen, zerlegen wir die Tweets in ihre einzelnen Strings, also Wörter. Da sich die Funktion unnest_tokens() hier allerdings nicht so gut anstellt, benötigen wir einen eigenen Tokenizer. Dieser ist so angepasst, dass Usernamen und Links in den Tweets nicht aufgenommen werden.\n\ntxt &lt;- \"@BabyAnimalPics: baby monkey bathtime http://t.co/7KPWAdLF0R Awwwwe! This is soooo ADORABLE!\"\n\nstr_split(txt, \"[:space:]+\") %&gt;%\n    map(~ str_remove_all(.x, \"@[^ ]+|https?[:graph:]+|^[:punct:]+|[:punct:]+\"))\n\n[[1]]\n [1] \"\"         \"baby\"     \"monkey\"   \"bathtime\" \"\"         \"Awwwwe\"  \n [7] \"This\"     \"is\"       \"soooo\"    \"ADORABLE\"\n\n\nDazu müssen noch alle möglichen Zahlen entfernt werden wie z.B. Unicodes von auf Twitter genutzten Emojis oder Geldbeträge. Alles zu einer Funktion kombiniert, könnte wie folgt aussehen:\n\ntokenize_words &lt;- function(x, lowercase = TRUE) {\n  if (lowercase)\n    x &lt;- str_to_lower(x)\n  \n  str_split(x, \"[:space:]\") %&gt;%\n    map(~ str_remove_all(.x, \n          \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|^[:punct:]+|[:punct:]+|\\\\d+\")) %&gt;% \n    unlist()\n}\n\nMal probieren ob es klappt:\n\nd_hate_regtok &lt;-\n  d_hate %&gt;%\n    mutate(word = map(tweet, tokenize_words)) %&gt;% \n  unnest(cols = word)%&gt;% \n  select(-tweet) %&gt;% \n  filter(!word == \"\")\nhead(d_hate_regtok)\n\n\n\n  \n\n\n\nSchon besser!\n\n\n\nEs befinden sich noch einige Strings in der Liste, die keine (analysierbaren) Wörter darstellen. Da hilft nur eines: Stopwörter entfernen! Hierzu kombiniere ich einige gängige Listen und ergänze sie mit einer eigenen, auf den Datensatz zugeschnittene Liste (z.B. “rt” ist die Abkürzung von “retweet”, “yall” als umgangssprachliche Form von “you all”).\n\nsw_snowball &lt;- get_stopwords(source = \"snowball\")\nsw_iso &lt;- get_stopwords(source = \"stopwords-iso\")\nsw_smart &lt;- get_stopwords(source = \"smart\")\nsw_tweet &lt;- tibble(word = c(\"rt\", \"da\", \"yall\", \"ur\", \"yo\", \"dat\", \"smh\", \"tho\", \"ya\", \"bout\", \"em\", \"dis\", \"bc\", \"dem\", \"ima\", \"|\", \"dc\", \"$\", \"+\"))\nsw_combi &lt;- \n  bind_rows(sw_snowball, sw_iso, sw_smart, sw_tweet) %&gt;% \n  select(-lexicon)\n\nd_hate_tok_wstop &lt;- \n  d_hate_regtok %&gt;% \n  anti_join(sw_combi)\n\nJoining with `by = join_by(word)`\n\nhead(d_hate_tok_wstop)\n\n\n\n  \n\n\n\n\n\n\nNun, da die Tweets in ihre einzelnen Wörter aufgeteilt und bereinigt sind, können wir wunderbar visualisieren was der Datensatz bereithält.\nWelche Wörter kommen am häufigsten vor?\n\nd_hate_tok_wstop %&gt;%\n  count(word, sort = TRUE) %&gt;% \n  slice_max(order_by = n, n = 20) %&gt;% \n  mutate(word = factor(word)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, n), x = n) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nDas ganze nochmal, aber jetzt nach Klassifikation sortiert:\n\nlibrary(reshape2)\n\n\nAttache Paket: 'reshape2'\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    smiths\n\nd_hate_tok_wstop %&gt;% \n  count(word, class, sort = TRUE) %&gt;%\n  acast(word ~ class, value.var = \"n\", fill = 0) %&gt;%\n  comparison.cloud(colors = c(\"#D55E00\", \"#56B4E9\",\n                              title.bg.colors=\"white\"),\n                   max.words = 100)\n\n\n\n\n“Man sieht: Es sind Schimpfwörter im Haus!” Das könnte für die weitere Analyse/ Klassifikation interessantwerden, ebenso wie mögliche Codewörter wie “brownie” (Personen mit dunkler Hautfarbe) oder “birds” (Frauen).\n\n\n\nDie Sentimentanalyse erkennt und bewertet den überwiegende “Ton” oder die “Stimmung” eines Textes. Dieser Prozess kann auf einzelne Sätze, Absätze oder sogar auf gesamte Dokumente angewendet werden. Wir konzentrieren uns hier einmal auf einzelne Wörter mithilfe des Lexikons afinn und einmal auf die Bewertung im Kontext eines ganzen Satzes mit dem Paket sentimentr.\nMit afinn:\n\nAFINN &lt;- get_sentiments(lexicon = \"afinn\")\n\n\nd_hate_senti &lt;-\nd_hate_tok_wstop %&gt;% \n  inner_join(AFINN, by = \"word\")\n\n\nd_hate_senti %&gt;% \n  group_by(class) %&gt;% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %&gt;% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %&gt;% round(2))\n\n\n\n  \n\n\n\nEs gibt ungefähr gleich viele polarisierende Wörter auf Seiten der Hate Speech und der Übrigen. Jedoch sind die Wörter unter Hate Speech deutlich stärker emotional negativ aufgeladen.\n\nd_hate_senti %&gt;% \n  ggplot() +\n  geom_density(aes(value, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nMit sentimentr:\n\nhate_sentir &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  sentiment() %&gt;% \n  filter(!word_count == 0)\n\n\nhate_sentir %&gt;% \n  ggplot() +\n  geom_density(aes(sentiment, fill = class, colour = class), alpha = 0.3) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nIm Vergleich zur Sentimenteinteilung von afinn sieht man hier eine ganz klare Spitze beim Wert der neutralen Bestandteile. Das liegt vor allem an der ungenauen Eintilung vom Befehl get_sentences(), der etliche Nicht-Sätze erstellt, die als neutral gewertet werden. Das könnte aber auch an der unterschiedlichen Herangehensweise, das Sentiment über die einzelnen Wörter bzw. im Kontext des gesamten Satzes zu ermitteln. Einzelne Wörter sind einfacher zu erkennen und eindeutiger zu bewerten.\nMit sentimentr kann man zusätzlich noch die Emotionen und Schimpfwörter analysieren.\n\nhate_emos &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion() %&gt;% \n  filter(!word_count == 0,\n         !emotion_count == 0)\n\n\nhate_emos %&gt;% \n  ggplot(aes(emotion_type, fill = class, colour = class)) +\n  geom_bar() +\n  scale_x_discrete(guide = guide_axis(angle = 60)) +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDas ist ein sehr großer Datensatz, deshalb will ich für jede id/ jeden Tweet die dominante Emotion herausfinden und darauf basierend den Datensatz verschlanken.\n\nhate_emos2 &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  emotion()\n\ndominant_emotion_df &lt;- \n  hate_emos2 %&gt;%\n  group_by(id, emotion_type) %&gt;%\n  summarize(weighted_score = sum(emotion_count * emotion)) %&gt;%\n  dplyr::slice(which.max(weighted_score)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\ndominant_emo_hate &lt;-\n  merge(d_hate, dominant_emotion_df, by = \"id\")\n\ndominant_emo_hate %&gt;% \n  ggplot(aes(class, emotion_type)) +\n  geom_bin2d() + \n  theme_minimal()\n\n\n\n\nKlappt!\nZwar muss bei dieser Grafik beachtet werden, dass der Anteil von other generell sehr viel größer ist, als der von hate speech und dementsprechend heller ist. Trotzdem kann man hier gut erkennen, welche Emotionen in den Tweets mit Hate Speech wohl vorherrscht: Wut, Ekel, Niedergeschlagenheit\nNun zu den Schimpfwörtern:\n\nhate_prof &lt;-\n  d_hate %&gt;% \n  sentimentr::get_sentences() %&gt;% \n  profanity() %&gt;% \n  filter(!word_count == 0)\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\nWarning in gsub(pattern[i], replacement[i], text.var, fixed = fixed, ..., :\nArgument 'perl = TRUE' wird ignoriert\n\n\nKritik: Das Schimpfwortlexikon von sentimentr listet das N-Wort in manchen Schreibweisen nicht als Schimpfwort!\n\nhate_prof %&gt;% \n  ggplot(aes(element_id, profanity_count, fill = class)) +\n  geom_bin_2d() +\n  scale_fill_manual(values = c(\"#D55E00\", \"#56B4E9\")) +\n  theme_minimal()\n\n\n\n\nDie Tweets, die einen hohen Anteil an Schimpfwörtern haben, sind eher unter hate speech gefallen, als andere.\n\n\n\nWord Embeddings sind eine Methode, um Textdaten als Vektoren von Zahlen darzustellen, basierend auf einem großen Textkorpus. Anders als bei tf_idf wird dabei die semantische Bedeutung aus dem Kontext der Wörter erfasst und die Textinformationen auf einen sehr dichte Raum reduziert. Aus diesem Grund tachen sie auch hier auf. Außerdem können wir dadurch erkennen, in welchem Kontext unsere angeblichen Codewörter stehen, und beurteilen, ob sie hier in erster Linie als solche verwendet werden.\n\ntidy_hate &lt;-\n  d_hate_tok_wstop %&gt;% \n  add_count(word) %&gt;% \n  filter(n &gt;= 15) %&gt;% \n  select(-n)\n\n\nnested_hate &lt;-\n  tidy_hate %&gt;% \n  nest(words = c(word))\n\n\nslide_windows &lt;- function(tbl, window_size) {\n  skipgrams &lt;- slider::slide(\n    tbl, \n    ~.x,  # Syntax ähnlich zu purrr::map()\n    .after = window_size - 1, \n    .step = 1, \n    .complete = TRUE\n  )\n    safe_mutate &lt;- safely(mutate)\n  \n  out &lt;- map2(skipgrams,\n              1:length(skipgrams),\n              ~ safe_mutate(.x, window_id = .y))\n  \n  out %&gt;%\n    transpose() %&gt;%\n    pluck(\"result\") %&gt;%\n    compact() %&gt;%\n    bind_rows()\n}\n\n\nhate_pmi &lt;- nested_hate %&gt;%\n  mutate(words = future_map(words, slide_windows, 4L)) %&gt;% \n  unnest(words) %&gt;% \n  unite(window_id, id, window_id) %&gt;% \n  pairwise_pmi(word, window_id)\n\nhate_pmi\n\n\n\n  \n\n\n\n\nhate_word_vectors &lt;- hate_pmi %&gt;%\n  widely_svd(\n    item1, item2, pmi,\n    nv = 100, maxit = 1000\n  )\n\n-&gt; Um zu entdecken, welche Wörter sich am nächsten stehen. Hier kommen die erwähnten Codewörter ins Spiel.\n\nnearest_neighbors &lt;- function(df, token) {\n  df %&gt;%\n    widely(\n      ~ {\n        y &lt;- .[rep(token, nrow(.)), ]\n        res &lt;- rowSums(. * y) / \n          (sqrt(rowSums(. ^ 2)) * sqrt(sum(.[token, ] ^ 2)))\n        \n        matrix(res, ncol = 1, dimnames = list(x = names(res)))\n      },\n      sort = TRUE\n    )(item1, dimension, value) %&gt;%\n    select(-item2)\n}\n\nFür Bird:\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"bird\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#CC79A7\") +\n  theme_minimal()\n\n\n\n\nDie Worte mit dem höchsten Wert lassen sich plausibel erklären und scheinen nicht sehr viel mit einem möglichen frauenverachtenden Codewort zu tun zu haben.(play, Flappy Birds, Angry Birds, games)\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"brownie\") %&gt;% \n  slice_max(order_by = value, n = 20) %&gt;%\n  mutate(word = factor(item1)) %&gt;% \n  ggplot() +\n  aes(y = reorder(word, value), x = value) +\n  geom_col(fill = \"#0072B2\") +\n  theme_minimal()\n\n\n\n\nHier beziehen sich die meisten Wörter auch auf das Gebäck, statt auf Menschen Bezug zu nehmen.\nUm nochmal sicher zu gehen, ob dieses Vorgehen auch verlässlich ist, probieren wir es mit einem offensichtlichen Begriff\n\nhate_word_vectors %&gt;% \n  nearest_neighbors(\"nigga\")\n\n\n\n  \n\n\n\nDefinitiv im Kontext negativerer Wörter!\nUm diese Embeddings für das spätere Modell zugänglich zu machen folgen noch ein paar Schritte.\n\nword_matrix &lt;- tidy_hate %&gt;%\n  count(id, word) %&gt;%\n  cast_sparse(id, word, n) \n\nembedding_matrix &lt;- hate_word_vectors %&gt;%\n  cast_sparse(item1, dimension, value)\n\n#doc_matrix &lt;- word_matrix %*% embedding_matrix\n#dim(doc_matrix)\n\n\nprint(dim(word_matrix))\n\n[1] 5235  309\n\nprint(dim(embedding_matrix))\n\n[1] 307 100\n\n\n\ndiff_matrix &lt;- dim(word_matrix) != dim(embedding_matrix)\ndiff_matrix\n\n[1] TRUE TRUE\n\n\nAus irgendeinem Grund gibt es einen Unterschied in den Matrizen, sodass ich sie nicht verbinden kann. Schade!\n\n\n\nn-grams stellen eine weitere Möglichkeit der Textanalyse dar, um Muster, Zusammenhänge und Beziehungen zwischen aufeinanderfolgenden Wörtern zu analysieren. Bigramme sind eine Sequenz von zwei aufeinanderfolgenden Elementen oder - in unserem Fall - Wörtern in einem Text. Als kleine Ergänzung zu den mögliche Codewörtern unter Word-Embeddings möchte ich hier noch einmal herausfinden welche Wörter denn wirklich häufig zusammen verwendet werden.\n\nbigrams_hate &lt;-\n  d_hate %&gt;% \n  unnest_tokens(bigram, tweet, token = \"ngrams\", n = 2)\n\n\nsw_erg &lt;- tibble(word = c(\"t.co\", \"128557\", \"128514\", \"ho\", \"8230\", \"9733\", \"https\", \"http\"))\nadded_sw &lt;- bind_rows(sw_combi, sw_erg)\n\n\nlibrary(igraph)\n\n\nAttache Paket: 'igraph'\n\n\nDie folgenden Objekte sind maskiert von 'package:future':\n\n    %-&gt;%, %&lt;-%\n\n\nDie folgenden Objekte sind maskiert von 'package:dials':\n\n    degree, neighbors\n\n\nDas folgende Objekt ist maskiert 'package:datawizard':\n\n    normalize\n\n\nDie folgenden Objekte sind maskiert von 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nDie folgenden Objekte sind maskiert von 'package:purrr':\n\n    compose, simplify\n\n\nDas folgende Objekt ist maskiert 'package:tidyr':\n\n    crossing\n\n\nDas folgende Objekt ist maskiert 'package:tibble':\n\n    as_data_frame\n\n\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    decompose, spectrum\n\n\nDas folgende Objekt ist maskiert 'package:base':\n\n    union\n\n(bigram_graph &lt;- bigrams_hate %&gt;% \n    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %&gt;%\n        filter(!word1 %in% added_sw$word,\n               !word2 %in% added_sw$word) %&gt;%\n        count(word1, word2, sort = TRUE) %&gt;%\n        unite(\"bigram\", c(word1, word2), sep = \" \") %&gt;%\n        filter(n &gt; 10) %&gt;%\n        graph_from_data_frame()\n)\n\nIGRAPH 9180658 DN-- 44 28 -- \n+ attr: name (v/c)\n+ edges from 9180658 (vertex names):\n [1] white trash   -&gt;66 flappy bird   -&gt;40 charlie crist -&gt;34 charlie sheen -&gt;26\n [5] charlie brown -&gt;25 derek jeter   -&gt;24 ass nigga     -&gt;22 charlie baker -&gt;21\n [9] trash talk    -&gt;21 0221 24       -&gt;19 622 0221      -&gt;19 asian massage -&gt;19\n[13] park slope    -&gt;19 rated spa     -&gt;19 uncle tom     -&gt;19 128525 128525 -&gt;17\n[17] yankee stadium-&gt;17 happy birthday-&gt;16 bitch ass     -&gt;15 rick scott    -&gt;15\n[21] 718 622       -&gt;14 ice cream     -&gt;14 red sox       -&gt;13 white people  -&gt;13\n[25] colored folk  -&gt;12 black people  -&gt;11 fucking faggot-&gt;11 trash 8221    -&gt;11\n\n\n\nlibrary(ggraph)\nset.seed(42)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n        geom_edge_link() +\n        geom_node_point(color = \"#CC79A7\", size = 5) +\n        geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n        theme_void()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDas mit Abstand am häufigsten vorkommende Bigramm ist “white trash”, dicht gefolgt von “flappy bird”. Anscheinend mussten viele ihren Frust an der digitalen Tastatur auslassen, nachdem sie das Spiel gespielt haben… Rassistsche und beleidigende Äußerungen wie “uncle tom” und “fucking faggot” sind ebenfalls vertreten, sowie das Stadion der New York Yankees und deren erfolgreicher Spieler Derek Jeter."
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html#modellierung",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html#modellierung",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Jetzt soll es aber endlich um die Vorhersage von Hate Speech gehen. Zuerst bleiben wir noch in R und bauen ein Klassifizierungsmodell für Hate Speech in tidymodels.Danach geht es weiter in Python und wir nutzen ein Large Language Model (LLM) für eine Zero-Shot-Learning-Vorhersage, also ohne vorheriges Fine-Tuning des LLM.\n\n\n\nhate_for_rec &lt;-\n  d_hate %&gt;% \n  mutate(tweet = str_remove_all(tweet, \"@[^ ]+|https?[:graph:]+|\\\\{\\\\$[0-9\\\\.]*\\\\}|[\\U{1F300}-\\U{1F6FF}]|\\\\d+\"))\n\n\nset.seed(42)\nhate_split &lt;- initial_split(hate_for_rec, strata = class)\n\ntrain_hate &lt;- training(hate_split)\ntest_hate &lt;- testing(hate_split)\n\n\n\n\nWir brauchen noch folgende Listen vorab, da sich die Befehle von sentimentr schlecht in ein recipe einfügen lassen. Das im default verwendete Schimpfwort-Lexikon von sentimentr ergänze ich noch um ein anderes mit rassistischem Vokabular.\n\ndata(hash_sentiment_jockers_rinker)\nView(hash_sentiment_jockers_rinker)\nhash &lt;- hash_sentiment_jockers_rinker %&gt;% \n  rename(word = x,\n         value = y)\n\nprofal &lt;- unique(tolower(profanity_alvarez)) \ndata(\"profanity_racist\")\nprofanity &lt;- as_tibble(c(profal, profanity_racist))\nprofanity &lt;- profanity %&gt;% \n  rename(word = value) %&gt;% \n  mutate(value = 1)\n\n\nrec1 &lt;-\n  recipe(class ~ ., data = train_hate) %&gt;% \n  update_role(id, new_role = \"id\") %&gt;% \n  update_role(tweet, new_role = \"ignore\") %&gt;% \n  step_text_normalization(tweet) %&gt;% \n  step_mutate(senta = get_sentiment(tweet, method = \"afinn\"),\n              sentr = get_sentiment(tweet, method = \"custom\", lexicon = hash), \n              profan = get_sentiment(tweet, method = \"custom\", lexicon = profanity))%&gt;% \n  step_tokenize(tweet, token = \"words\") %&gt;%\n  step_stopwords(tweet, custom_stopword_source = \"sw_combi\") %&gt;% \n  step_tokenfilter(tweet, max_tokens = 1e2) %&gt;% \n  step_tfidf(tweet) %&gt;% \n  step_zv(all_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors())\n\nbaked &lt;- bake(prep(rec1), new_data = NULL)\n\n\n\n\nmod1 &lt;-\n  boost_tree(mtry = tune(), \n            min_n = tune(), \n            trees = tune(),\n            tree_depth = tune(),\n            learn_rate = tune(),\n            loss_reduction = tune(),\n           mode = \"classification\") %&gt;% \n  set_engine(\"xgboost\", nthreads = 4)\n\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n\n\n\nset.seed(42)\nrsmpl &lt;- vfold_cv(train_hate, v = 3, repeats = 2)\n\n\n\n\n\ntic()\nwf_tune &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl,\n    grid = 5, \n    seed = 42,\n    metrics = metric_set(accuracy, f_meas, roc_auc),\n    control = control_grid(verbose = TRUE, save_workflow = TRUE))\n\nWarning: The `...` are not used in this function but one or more objects were\npassed: 'seed'\n\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\ni Fold1, Repeat1: preprocessor 1/1\n\n\nv Fold1, Repeat1: preprocessor 1/1\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold1, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold1, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1\n\n\nv Fold2, Repeat1: preprocessor 1/1\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold2, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold2, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1\n\n\nv Fold3, Repeat1: preprocessor 1/1\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 1/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 2/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 3/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 4/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5\n\n\nv Fold3, Repeat1: preprocessor 1/1, model 5/5\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold3, Repeat1: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1\n\n\nv Fold1, Repeat2: preprocessor 1/1\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold1, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold1, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1\n\n\nv Fold2, Repeat2: preprocessor 1/1\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold2, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold2, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1\n\n\nv Fold3, Repeat2: preprocessor 1/1\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 1/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 1/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 2/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 2/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 3/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 3/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 4/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 4/5 (predictions)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5\n\n\nv Fold3, Repeat2: preprocessor 1/1, model 5/5\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5 (extracts)\n\n\ni Fold3, Repeat2: preprocessor 1/1, model 5/5 (predictions)\n\ntoc()\n\n552.01 sec elapsed\n\n\n\ntune::autoplot(wf_tune) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nmetrics &lt;-\nwf_tune %&gt;% \n  collect_metrics() \nmetrics %&gt;% \n  arrange(-mean) %&gt;% \n  head()\n\n\n\n  \n\n\n\n-&gt; Preprocessor1_Model5 schneidet am besten ab.\n\n\n\n\nfinal_fit &lt;- \n  fit_best(wf_tune)\n\n[18:44:41] WARNING: amalgamation/../src/learner.cc:627: \nParameters: { \"nthreads\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\nWelche Prädiktoren waren bei diesem Modell die wichtigsten?\n\nfinal_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 15, geom = \"point\") +\n  theme_minimal()\n\n\n\n\nWie schon in der EDA vermutet, nehmen Schimpfwörter einen sehr prominenten Wert in der Vorhersage ein. Zusammen mit den beiden Sentiment-Lexika und dem tf_idf-Wert für “white” führt es die Liste an.\n\n\n\n\npred_test &lt;- \n  final_fit %&gt;% \n  predict(new_data = test_hate) %&gt;% \n  bind_cols(test_hate)\n\n\npred_test1 &lt;-\n  pred_test %&gt;% \n  mutate(class = as_factor(class),\n         .pred_class = ifelse(.pred_class == \"hate speech\", 1, 0)) %&gt;% \n  mutate(class = ifelse(class == \"hate speech\", 1, 0))\n\nrocobj &lt;- \n  pred_test1 %&gt;% \n  roc(class, .pred_class)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#0072B2\", size = 1.5)\n\n\n\n\nObwohl unsere Vorhersage im Train-Sample eine accuracy von ca. 89% aufweist, liegt die ROC-Kurve für die Vorhersage auf das Test-Sample unter der Zufallslinie. Das bedeutet, dass unser Klassifikator schlechter ist, als zufällige Vorhersagen… Schade! Vielleicht ist es besser mit einem Transformer-Modell ;)"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html#transformer-modell",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html#transformer-modell",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Wir nutzen Transformer-Modelle über die Huggingface-API für unser Zero-Shot-Learning. Ich habe mich hier für das Modell entschieden, das im Bezug auf Hate-Speech-Detection im Internet am häufigsten heruntergeladen wurde und sich in den Suchvorschlägen ganz oben befindet.\n\n\n\nimport tensorflow as tf\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\n\ntweet &lt;- test_hate$tweet\n\n\nhate_py = r.tweet\n\n\n\n\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\BLUMSB~1\\DSIIVI~1\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n\n\n\nresult = classifier(hate_py)\n\n\n\n\n…um die Ergebnisse der Vorhersage des Transformer-Modells vergleichen zu können.\n\nr_results &lt;- py$result\nhead(r_results)\n\n[[1]]\n[[1]]$label\n[1] \"nothate\"\n\n[[1]]$score\n[1] 0.9998609\n\n\n[[2]]\n[[2]]$label\n[1] \"nothate\"\n\n[[2]]$score\n[1] 0.8565221\n\n\n[[3]]\n[[3]]$label\n[1] \"nothate\"\n\n[[3]]$score\n[1] 0.6914555\n\n\n[[4]]\n[[4]]$label\n[1] \"hate\"\n\n[[4]]$score\n[1] 0.9997545\n\n\n[[5]]\n[[5]]$label\n[1] \"nothate\"\n\n[[5]]$score\n[1] 0.998069\n\n\n[[6]]\n[[6]]$label\n[1] \"nothate\"\n\n[[6]]$score\n[1] 0.9973779\n\n\n\nlabel &lt;- map(r_results, ~.$label)\n\npred_hate_py &lt;- \n  bind_cols(pred_test1, pred_py = unlist(label))\n\npred_hate_py &lt;- \n  pred_hate_py %&gt;%\n  mutate(pred_py = case_when(pred_py == \"hate\" ~ \"hate speech\",\n                             pred_py == \"nothate\" ~ \"other\"))  %&gt;%\n  mutate(pred_py = ifelse(pred_py == \"hate speech\", 1, 0))\n\n\nrocobj &lt;- \n  pred_hate_py %&gt;% \n  roc(class, pred_py)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nggroc(rocobj, colour = \"#E69F00\", size = 1.5)\n\n\n\n\nOk, diese Form der “Kurve” weist Ähnlichkeiten zu der Kurve meines eigenen Modells auf… Allerdings hat dieses Modell einen steileren Anstieg, was beseutet, dass der Klassifikator mit höherer Genauigkeit positive Vorhersagen trifft, bevor viele falsch positive Vorhersagen gemacht werden.\n\ndiff_pred &lt;- \n  pred_hate_py %&gt;%\n  group_by(class) %&gt;%\n  count(pred_py != .pred_class)\ndiff_pred\n\n\n\n  \n\n\n\nIm direkten Vergleich haben das Transformer-Modell von Huggingface und mein tidymodels-Modell 269 Werte verschieden bewertet. Unter Nicht-Hate Speech gab es etwas mehr Unstimmigkeiten als bei Hate Speech selbst."
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html#fazit",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html#fazit",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Die Klassifikation von Hate Speech in sozialen Netzwerken bleibt ein Buch mit vielen Siegeln. Eine nahezu perfekte Vorhersage, wird es wahrscheinlich in naher Zukunft nicht geben. Dafür gibt es zu viele Limitationen des Algorithmus. Nicht ohne Grund beschweren sich v.a. viele Comedians/ Internet-Clowns, dass ihre Accounts aufgrund von angeblicher Hassrede/ Hetze gesperrt werden, obwohl sie sich satirisch/ ironisch äußern. Auch die in diesem Blog schon mehrfach erwähnten Codewörter für Beleidigungen/ rassistische Bezeichnugnen werden nicht weniger. Das kann man am Beispiel von Chinas Staatsoberhaupt Xi veranschaulichen.\n“According to the censorship log leaked by the social media app Xiaohongshu in 2020, 564 words were considered “sensitive” by the Chinese government when referring to Xi.” Xiao H., 2023 (https://wagingnonviolence.org/2023/04/how-subvversive-nicknames-for-china-present-xi-jinping-fuel-dissent/; abgerufen am 09.02.24)\n… und es werden nicht weniger! Dennoch stellt dieser Blog einige Ansatzpunkte und verschiedene Möglichkeiten dar, die zumindest ein paar der Siegel öffnen können. Alles darüber hinaus wird die Zukunft bringen!"
  },
  {
    "objectID": "posts/Pruefungsleistung/pruefungsleistung.html#quellen-weitere-informationen",
    "href": "posts/Pruefungsleistung/pruefungsleistung.html#quellen-weitere-informationen",
    "title": "Prüfungsleistung DSii",
    "section": "",
    "text": "Dieser Blogbeitrag orientiert sich an den Kursinhalten des Schwerpunktmoduls “Data Science 2” im Studiengang “Angewandte Wirtschafts- & Medienpsychologie”, betreut von Prof. Dr. habil. Sebastian Sauer.\nSebastian Sauer. (2023). sebastiansauer/datascience-text: v0.1.0 (Version draft1). Zenodo. https://doi.org/10.5281/zenodo.8279822.\n\n\n\nsessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28    stringi_1.7.6      ggraph_2.1.0       igraph_1.4.2      \n [5] reshape2_1.4.4     pROC_1.18.0        caret_6.0-94       lattice_0.20-45   \n [9] vip_0.4.1          tictoc_1.2         xgboost_1.6.0.1    lexicon_1.2.1     \n[13] syuzhet_1.0.7      tokenizers_0.3.0   textrecipes_1.0.3  furrr_0.3.1       \n[17] future_1.33.0      irlba_2.3.5.1      Matrix_1.5-4       widyr_0.1.5       \n[21] sentimentr_2.9.0   wordcloud_2.6      RColorBrewer_1.1-3 stopwords_2.3     \n[25] yardstick_1.1.0    workflowsets_1.0.1 workflows_1.1.3    tune_1.1.2        \n[29] rsample_1.2.0      recipes_1.0.9      parsnip_1.0.4      modeldata_1.2.0   \n[33] infer_1.0.5        dials_1.2.0        scales_1.2.1       broom_1.0.5       \n[37] tidymodels_1.0.0   see_0.8.1          report_0.5.7       parameters_0.21.0 \n[41] performance_0.10.3 modelbased_0.8.6   insight_0.19.2     effectsize_0.8.3  \n[45] datawizard_0.7.1   correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0   \n[49] tidytext_0.4.1     forcats_0.5.1      stringr_1.5.0      dplyr_1.1.2       \n[53] purrr_1.0.1        readr_2.1.2        tidyr_1.2.0        tibble_3.2.1      \n[57] ggplot2_3.4.4      tidyverse_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.3.1         backports_1.4.1      plyr_1.8.8          \n  [4] splines_4.1.3        listenv_0.9.0        SnowballC_0.7.0     \n  [7] digest_0.6.29        foreach_1.5.2        htmltools_0.5.5     \n [10] viridis_0.6.4        fansi_1.0.2          magrittr_2.0.2      \n [13] tzdb_0.3.0           graphlayouts_0.8.4   globals_0.16.2      \n [16] modelr_0.1.11        gower_1.0.1          vroom_1.6.1         \n [19] textshape_1.7.3      hardhat_1.3.0        colorspace_2.0-3    \n [22] ggrepel_0.9.3        rappdirs_0.3.3       rvest_1.0.3         \n [25] warp_0.2.0           haven_2.4.3          xfun_0.39           \n [28] crayon_1.5.2         jsonlite_1.8.4       survival_3.2-13     \n [31] iterators_1.0.14     glue_1.6.2           polyclip_1.10-4     \n [34] gtable_0.3.4         ipred_0.9-14         future.apply_1.11.0 \n [37] DBI_1.1.3            qdapRegex_0.7.8      Rcpp_1.0.8          \n [40] viridisLite_0.4.2    bit_4.0.5            GPfit_1.0-8         \n [43] textclean_0.9.3      stats4_4.1.3         lava_1.7.3          \n [46] prodlim_2023.03.31   htmlwidgets_1.6.2    httr_1.4.7          \n [49] ellipsis_0.3.2       farver_2.1.1         pkgconfig_2.0.3     \n [52] nnet_7.3-17          dbplyr_2.3.2         here_1.0.1          \n [55] utf8_1.2.2           labeling_0.4.3       tidyselect_1.2.0    \n [58] rlang_1.1.2          DiceDesign_1.9       munsell_0.5.0       \n [61] cellranger_1.1.0     tools_4.1.3          cli_3.6.0           \n [64] generics_0.1.3       evaluate_0.23        fastmap_1.1.0       \n [67] yaml_2.3.5           textdata_0.4.4       bit64_4.0.5         \n [70] ModelMetrics_1.2.2.2 knitr_1.37           fs_1.5.2            \n [73] tidygraph_1.2.3      nlme_3.1-155         xml2_1.3.3          \n [76] compiler_4.1.3       rstudioapi_0.15.0    png_0.1-8           \n [79] slider_0.3.0         reprex_2.0.2         tweenr_2.0.2        \n [82] lhs_1.1.6            vctrs_0.6.1          pillar_1.9.0        \n [85] lifecycle_1.0.4      data.table_1.14.8    R6_2.5.1            \n [88] gridExtra_2.3        janeaustenr_1.0.0    parallelly_1.36.0   \n [91] codetools_0.2-18     MASS_7.3-55          rprojroot_2.0.4     \n [94] withr_2.5.2          parallel_4.1.3       hms_1.1.3           \n [97] grid_4.1.3           rpart_4.1.16         timeDate_4032.109   \n[100] class_7.3-20         rmarkdown_2.25       ggforce_0.4.1       \n[103] lubridate_1.8.0"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]